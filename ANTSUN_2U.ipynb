{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Automatic Neuron Tracking System for Unconstrained Nematodes (ANTSUN) v2.1.0-Unsupervised***\n",
    "\n",
    "This notebook performs unsupservised NeuroPAL neuron labeling. It takes as input a fully-trained CellDiscoveryNet and a directory containing 4-D multispectral images of worms, their ROI (segmentation) images, and Euler-registered versions for every pair of images.\n",
    "\n",
    "Note that it is assumed that Euler registration (including rotating the worms to lie on the same side) should already be performed BEFORE running this notebook, and it is also assumed that you've already trained CellDiscoveryNet. If you haven't done so, please refer to the training notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GPU and server version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_smi_device = 0\n",
    "flv_c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flv_c == 1\n",
    "    gpu_device = 0\n",
    "elseif flv_c == 2\n",
    "    if nvidia_smi_device < 2\n",
    "        gpu_device = nvidia_smi_device + 2\n",
    "    else\n",
    "        gpu_device = nvidia_smi_device - 2\n",
    "    end\n",
    "elseif flv_c == 3\n",
    "    if nvidia_smi_device < 2\n",
    "        gpu_device = 1 - nvidia_smi_device\n",
    "    else\n",
    "        gpu_device = nvidia_smi_device\n",
    "    end\n",
    "else\n",
    "    error(\"Unsupported flv-c version\")\n",
    "end \n",
    "gpu_device = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"CUDA_VISIBLE_DEVICES\"] = \"$(gpu_device)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flavell lab packages\n",
    "using ND2Process\n",
    "using GPUFilter\n",
    "using WormFeatureDetector\n",
    "using NRRDIO\n",
    "using FlavellBase\n",
    "using SegmentationTools\n",
    "using ImageDataIO\n",
    "using RegistrationGraph\n",
    "using ExtractRegisteredData\n",
    "using CaAnalysis\n",
    "using BehaviorDataNIR\n",
    "using UNet2D\n",
    "using ImageRegistration\n",
    "\n",
    "# Other packages\n",
    "using ProgressMeter\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using DelimitedFiles\n",
    "using Images\n",
    "using Cairo\n",
    "using Distributions\n",
    "using DataStructures\n",
    "using HDF5\n",
    "using Interact\n",
    "using WebIO\n",
    "using Plots\n",
    "# using GraphPlot\n",
    "# using LightGraphs\n",
    "# using SimpleWeightedGraphs\n",
    "using Dates\n",
    "using JLD2\n",
    "using TotalVariation\n",
    "using VideoIO\n",
    "using Distributions\n",
    "using MultivariateStats\n",
    "using FFTW\n",
    "using LinearAlgebra\n",
    "using GLMNet\n",
    "using InformationMeasures\n",
    "using CUDA\n",
    "using LsqFit\n",
    "using Optim\n",
    "using Rotations\n",
    "using CoordinateTransformations\n",
    "using ImageTransformations\n",
    "using Interpolations\n",
    "using H5Zblosc\n",
    "using SparseArrays\n",
    "using StatsPlots\n",
    "\n",
    "using Distributed\n",
    "using Clustering\n",
    "using CSV\n",
    "using DataFrames\n",
    "using LaTeXStrings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset path parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`path_root_process_*` will be the output directories that this notebook will write to.\n",
    "\n",
    "`root_path_data` is the directory containing the input data.\n",
    "\n",
    "Most other parameters should not need to be changed from their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ND2 parameters\n",
    "ch_bluegreen = 1 # GCaMP and BFP\n",
    "ch_red = 2 # mNeptune\n",
    "n_rec = 1 # number of Illumination Sequence module recordings (.nd2) in the HDF5 file \n",
    "h5_confocal_time_lag = 0 # if this is the second confocal dataset using the same h5 file, set equal to number of frames in 1st dataset\n",
    "spacing_lat = 0.54 # Spacing of each voxel in the xy plane. If different, it will likely be necessary to modify pipeline parameters.\n",
    "spacing_axi = 0.54 # Spacing of each voxel in the z dimension. If different, it will likely be necessary to modify pipeline parameters.\n",
    "\n",
    "## Path to data directory\n",
    "data_dir = \"/data4\"\n",
    "\n",
    "## Freely-moving parameters\n",
    "max_graph_num = 800 # time point just before laser intensity is changed in freely-moving dataset. If not changed, set to length of the dataset.\n",
    "blue_laser = [13,15] # array of blue laser values before vs after param[\"max_graph_num\"] in the freely-moving dataset\n",
    "green_laser = [15,17] # array of green laser values before vs after param[\"max_graph_num\"] in the freely-moving dataset\n",
    "\n",
    "\n",
    "## Data path parameters\n",
    "prj = \"prj_register\" # change to your project - ie: the location to save the data\n",
    "path_raw_data = \"\" # change to the directory with all raw data files\n",
    "\n",
    "datasets = Dict() # for each filter, update the corresponding entry in the dictionary the path to the ND2 file for that dataset (without the .nd2 extension)\n",
    "datasets[\"freely_moving\"] = \"multicolor_deepreg_test_6\"\n",
    "\n",
    "\n",
    "## You should not need to change anything below this line except possibly `reg_timepts[dataset] = 30`.\n",
    "datasets_freely_moving = [\"freely_moving\"] # freely-moving datasets\n",
    "dataset_central = \"freely_moving\" # central dataset - register other datasets to this. Must contain camera-alignment registration\n",
    "datasets_register = [] # datasets to register back to central dataset\n",
    "\n",
    "n_timepts_merge = Dict() # number of registrations to attempt back to the central dataset, for each registered dataset\n",
    "for dataset in datasets_register\n",
    "    n_timepts_merge[dataset] = 200\n",
    "end\n",
    "\n",
    "## Immobilized parameters\n",
    "reg_timepts = Dict()\n",
    "for dataset in keys(datasets)\n",
    "    if dataset in datasets_freely_moving\n",
    "        continue\n",
    "    end\n",
    "    reg_timepts[dataset] = 30 # timepoint to register everything to, for the immobilized datasets\n",
    "end\n",
    "\n",
    "\n",
    "rotate_img_x = false # whether to rotate the image about the x-axis (if the worm was put on the slide the wrong way)\n",
    "\n",
    "fm = datasets[\"freely_moving\"]\n",
    "path_root_process_freelymoving = \"$(data_dir)/$(prj)/data_processed/$(fm)_output\"\n",
    "path_root_process_immobilized = \"$(data_dir)/$(prj)/data_processed/$(fm)_output/neuropal\"\n",
    "\n",
    "create_dir(path_root_process_freelymoving)\n",
    "create_dir(path_root_process_immobilized)\n",
    "\n",
    "root_path_data = \"/data4/prj_register/multicolor_deepreg_test_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_paths = Dict()\n",
    "params = Dict()\n",
    "data_dicts = Dict()\n",
    "error_dicts = Dict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set various directory paths\n",
    "\n",
    "There's a lot of paths going on here, most of which can be left at default values. (This code block is imported from ANTSUN 2.1.0, but many steps are skipped in this notebook.)\n",
    "\n",
    "However, the entry `param_path[\"path_deepreg_weights\"]` should be set to the path of the trained CellDiscoveryNet weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in keys(datasets)\n",
    "    exp_prefix = datasets[dataset]\n",
    "    if dataset in datasets_freely_moving\n",
    "        path_root_process = path_root_process_freelymoving\n",
    "    else\n",
    "        path_root_process = joinpath(path_root_process_immobilized, datasets[dataset])\n",
    "    end\n",
    "    \n",
    "    if !(dataset in keys(params))\n",
    "        params[dataset] = Dict()\n",
    "    end\n",
    "    param = params[dataset]\n",
    "    \n",
    "    if !(dataset in keys(param_paths))\n",
    "        param_paths[dataset] = Dict{String,Any}()\n",
    "    end\n",
    "    param_path = param_paths[dataset]\n",
    "\n",
    "    param_path[\"path_root_process\"] = path_root_process\n",
    "\n",
    "    param_path[\"path_unet_pred\"] = \"/home/adam/src/pytorch-3dunet/pytorch3dunet/predict.py\" # Path to the pytorch-3dunet installation on the local machine\n",
    "    param_path[\"path_unet_param\"] = \"/data3/shared/dl_weights/3dunet_NeuroPAL/instance_segmentation_test.yaml\" # Path to the UNet parameter file\n",
    "    param_path[\"path_unet_py_env\"] = \"/home/adam/.julia/conda/3/bin/activate\" # Path to a script that should be run to configure environment variables for the pytorch-3dunet\n",
    "    param_path[\"path_transformix\"] = (flv_c == 2) ? \"/bin/transformix\" : \"/usr/local/bin/transformix\" # Path to transformix executable on the LOCAL machine\n",
    "    param_path[\"path_elastix_local\"] = (flv_c > 1) ? \"/bin/elastix\" : \"/usr/local/bin/elastix\" # Path to elastix executable on the LOCAL machine\n",
    "\n",
    "    \n",
    "    param_path[\"path_head_unet_model\"] = \"/data1/shared/head_detector_0124/head_detector_0124/unet2d-head-detector/unet2d-head-detector_best.pt\" # path to head detection unet model\n",
    "    param_path[\"path_2d_unet_param\"] = \"/data3/shared/dl_weights/behavior_nir/worm_segmentation_best_weights_0310.pt\"\n",
    "\n",
    "    param_path[\"path_dir_lock\"] = \"/home/adam/lock\" # path to lock directory\n",
    "\n",
    "    if dataset in datasets_freely_moving\n",
    "        param_path[\"path_head_rotate\"] = \"/om2/group/flavell/script/registration/euler_registration/euler_head_rotate.py\"\n",
    "    else\n",
    "        param_path[\"path_head_rotate\"] = nothing\n",
    "    end\n",
    "    param_path[\"path_head_rotate_activity_marker\"] = nothing\n",
    "    param_path[\"path_elastix\"] = \"/om2/user/aaatanas/elastix-5.0.1/build/bin/elastix\"\n",
    "    param_path[\"path_run_elastix\"] = \"/om2/group/flavell/script/registration/run_elastix_command.sh\"\n",
    "\n",
    "    om_user = \"aaatanas\" # Your username on OpenMind\n",
    "    param_path[\"path_om_home\"] = \"/om2/user/$om_user\"\n",
    "    param_path[\"path_om_env\"] = \"/home/$(om_user)/.bashrc\" # path to user environment variable script on OpenMind\n",
    "    param_path[\"path_om_data\"] = joinpath(param_path[\"path_om_home\"], \"$(exp_prefix)_output\")\n",
    "    param_path[\"path_om_home_scripts\"] = \"/om2/user/$om_user\"\n",
    "    param_path[\"path_om_scripts\"] = joinpath(param_path[\"path_om_home_scripts\"], \"$(exp_prefix)_output\")\n",
    "\n",
    "    param_path[\"path_om_euler_param\"] = \"/om2/group/flavell/script/registration/elastix_parameters/parameters_freely_moving_euler.txt\" # Path to Euler parameter file on OpenMind\n",
    "    param_path[\"path_om_euler_am_param\"] = \"/om2/group/flavell/script/registration/elastix_parameters/parameters_freely_moving_euler_output.txt\" # Path to Euler parameter file on OpenMind\n",
    "    param_path[\"path_om_affine_param\"] = \"/om2/group/flavell/script/registration/elastix_parameters/parameters_freely_moving_affine.txt\" # Path to Affine parameter file on OpenMind\n",
    "    \n",
    "    if dataset in datasets_freely_moving\n",
    "        param_path[\"path_om_bspline_param\"] = \"/om2/group/flavell/script/registration/elastix_parameters/parameters_freely_moving_bspline.txt\" # Path to BSpline parameter file on OpenMind\n",
    "        param[\"max_graph_num\"] = max_graph_num # maximum length before graph split\n",
    "        param[\"blue_laser\"] = blue_laser\n",
    "        param[\"green_laser\"] = green_laser\n",
    "        \n",
    "        param[\"blue_zero_thresh\"] = 4.5\n",
    "        param[\"blue_min_laser\"] = 5.2\n",
    "        param[\"blue_max_interpolate\"] = 2.0\n",
    "\n",
    "        param[\"green_zero_thresh\"] = 7.0\n",
    "        param[\"green_min_laser\"] = 7.7\n",
    "        param[\"green_max_interpolate\"] = 2.0\n",
    "\n",
    "        intensity = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"488nm/1/intensity\")\n",
    "        laser_perc = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"488nm/1/laser_percent\")\n",
    "\n",
    "        intensity2 = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"488nm/2/intensity\")\n",
    "        laser_perc2 = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"488nm/2/laser_percent\")\n",
    "        \n",
    "        param[\"blue_laser_intensity\"] = (intensity .+ intensity2) ./ 2\n",
    "        param[\"blue_laser_perc\"] = laser_perc\n",
    "\n",
    "        param[\"green_laser_intensity\"] = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"561nm/1/intensity\")\n",
    "        param[\"green_laser_perc\"] = h5read(\"/data3/shared/2022-05-11-laser-power.h5\", \"561nm/1/laser_percent\");\n",
    "        \n",
    "        param[\"good_registration_resolutions\"] = [(0,0)] #= which registration resolutions\n",
    "            are good enough to extract data from =#\n",
    "        param[\"reg_n_resolution\"] = [0,0,4]\n",
    "\n",
    "        param[\"good_registration_resolutions_to_immobilized\"] = [(2,0),(2,1),(2,2),(2,3)]\n",
    "\n",
    "        @assert(laser_perc == laser_perc2)\n",
    "        \n",
    "        # NeuroPAL labeling settings\n",
    "        param_path[\"path_root_process_label\"] = joinpath(path_root_process, \"neuropal_label\")\n",
    "        create_dir(param_path[\"path_root_process_label\"])\n",
    "        param_path[\"path_neuropal_img\"] = joinpath(param_path[\"path_root_process_label\"], \"NeuroPAL.nrrd\")\n",
    "        param_path[\"path_neuropal_img_mNeptune_GCaMP\"] = joinpath(param_path[\"path_root_process_label\"], \"NeuroPAL_mNeptune_GCaMP_bleedthrough.nrrd\")\n",
    "        param_path[\"path_bfp_img\"] = joinpath(param_path[\"path_root_process_label\"], \"BFP.nrrd\")\n",
    "        param_path[\"path_ofp_img\"] = joinpath(param_path[\"path_root_process_label\"], \"OFP.nrrd\")\n",
    "        param_path[\"path_gcamp_img\"] = joinpath(param_path[\"path_root_process_label\"], \"OFP_GCaMP.nrrd\") # actual GCaMP\n",
    "        param_path[\"path_mNeptune_img\"] = joinpath(param_path[\"path_root_process_label\"], \"mNeptune.nrrd\")\n",
    "        param_path[\"path_mNeptune_gcamp_img\"] = joinpath(param_path[\"path_root_process_label\"], \"mNeptune_GCaMP_bleedthrough.nrrd\") # GCaMP bleedthrough\n",
    "        param_path[\"path_all_red_img\"] = joinpath(param_path[\"path_root_process_label\"], \"all_red.nrrd\")\n",
    "        param_path[\"path_neuron_img\"] = joinpath(param_path[\"path_root_process_label\"], \"neuron_rois.nrrd\")\n",
    "        param_path[\"path_dir_autolabel_input\"] = joinpath(param_path[\"path_root_process_label\"], \"autolabel_data\")\n",
    "        param_path[\"path_h5_autolabel_input\"] = joinpath(param_path[\"path_dir_autolabel_input\"], \"NeuroPAL.h5\")\n",
    "        param_path[\"path_neuron_img_crop\"] = joinpath(param_path[\"path_root_process_label\"], \"neuron_rois_cropped.h5\")\n",
    "        param_path[\"path_autolabel_csv\"] = joinpath(param_path[\"path_root_process_label\"], \"labels.csv\")\n",
    "        param_path[\"path_autolabel_param\"] = \"/data3/shared/dl_weights/NeuroPAL_autolabel_release/v2/instance_segmentation_test.yaml\"\n",
    "        param_path[\"path_autolabel_neuron_ids\"] = \"/data3/shared/dl_weights/NeuroPAL_autolabel_release/v2/extracted_neuron_ids.h5\"\n",
    "\n",
    "        param[\"crop_size\"] = (284, 120, 64, 4)\n",
    "\n",
    "        # Deepnet registration settings\n",
    "        np = pyimport(\"numpy\")\n",
    "\n",
    "        param_path[\"path_dir_nrrd_filt_recropped\"] = joinpath(param_path[\"path_root_process\"], \"NRRD_filtered_recropped\")\n",
    "        param_path[\"path_dir_roi_watershed_recropped\"] = joinpath(param_path[\"path_root_process\"], \"img_roi_watershed_recropped\")\n",
    "        param_path[\"path_dir_ch1_recropped\"] = joinpath(param_path[\"path_root_process\"], \"ch1_recropped\")\n",
    "        param_path[\"path_dir_ch1_registered\"] = joinpath(param_path[\"path_root_process\"], \"ch1_registered\")\n",
    "        param_path[\"path_deepreg_weights\"] = \"/data4/prj_register/multicolor_deepreg_test_5/multicolor_gncc/save/ckpt-596\"\n",
    "        param_path[\"path_deepreg_config\"] = \"/data3/shared/dl_weights/deepreg/large_crop/config.yaml\"\n",
    "        \n",
    "        param_path[\"path_dir_nrrd_filt_recropped\"] = joinpath(param_path[\"path_root_process\"], \"NRRD_filtered_recropped\")\n",
    "        create_dir(param_path[\"path_dir_nrrd_filt_recropped\"])\n",
    "\n",
    "        param[\"deepreg_batch_size\"] = 3\n",
    "        if flv_c == 3 && nvidia_smi_device == 1\n",
    "            param[\"deepreg_batch_size\"] = 6\n",
    "        end\n",
    "        if flv_c == 2 && nvidia_smi_device < 2\n",
    "            param[\"deepreg_batch_size\"] = 2\n",
    "        end\n",
    "        param[\"deepreg_label_size\"] = (200, 3)\n",
    "        \n",
    "\n",
    "        param[\"euler_downsample_factor\"] = 4\n",
    "        param[\"euler_batch_size\"] = 5000\n",
    "        param[\"euler_x_translation_range_1\"] = np.sort(np.concatenate((\n",
    "            np.linspace(-0.24, 0.24, 49),\n",
    "            np.linspace(-0.46, -0.25, 8),\n",
    "            np.linspace(0.25, 0.46, 8),\n",
    "            np.linspace(0.5, 1, 3),\n",
    "            np.linspace(-1, -0.5, 3))))\n",
    "        param[\"euler_x_translation_range_2\"] = np.zeros(1)\n",
    "        param[\"euler_y_translation_range_1\"] = np.sort(np.concatenate((\n",
    "            np.linspace(-0.28, 0.28, 29),\n",
    "            np.linspace(-0.54, -0.3, 5),\n",
    "            np.linspace(0.3, 0.54, 5),\n",
    "            np.linspace(0.6, 1.4, 3),\n",
    "            np.linspace(-1.4, -0.6, 3))))\n",
    "        param[\"euler_y_translation_range_2\"] = np.zeros(1)\n",
    "        param[\"euler_z_translation_range_1\"] = np.linspace(-1.0, 1.0, 201)\n",
    "        param[\"euler_z_translation_range_2\"] = np.zeros(1)\n",
    "        param[\"euler_theta_rotation_range_xy\"] = np.sort(np.concatenate((\n",
    "            np.linspace(0, 19, 20),\n",
    "            np.linspace(20, 160, 29),\n",
    "            np.linspace(161, 199, 39),\n",
    "            np.linspace(200, 340, 29),\n",
    "            np.linspace(341, 359, 19))))\n",
    "        param[\"euler_theta_rotation_range_xz\"] = np.zeros(1)\n",
    "        param[\"euler_theta_rotation_range_yz\"] = np.zeros(1)\n",
    "\n",
    "        create_dir(param_paths[dataset_central][\"path_dir_roi_watershed_recropped\"])\n",
    "        create_dir(param_paths[dataset][\"path_dir_nrrd_filt_recropped\"])\n",
    "        \n",
    "    else\n",
    "        param_path[\"path_om_bspline_param\"] = \"/om2/group/flavell/script/registration/elastix_parameters/parameters_immobilized_bspline.txt\" # Path to BSpline parameter file on OpenMind\n",
    "        param[\"reg_timept\"] = reg_timepts[dataset]\n",
    "        param[\"reg_n_resolution\"] = [0,0,2] # the number of euler, affine and BSpline registrations\n",
    "        param[\"good_registration_resolutions\"] = [(2,0), (2,1)] #= which registration resolutions\n",
    "            are good enough to extract data from =#\n",
    "        param[\"registration_resolution_neuropal\"] = (0,1) # registration resolution for neuroPAL immobilized registration\n",
    "    end\n",
    "\n",
    "    # BFP camera alignment settings\n",
    "    if dataset == \"BFP\"\n",
    "        param[\"use_camera_alignment\"] = true\n",
    "        \n",
    "        param_path[\"path_camera_alignment\"] = joinpath(path_root_process, \"camera_align_BFP\")\n",
    "        param_path[\"path_elastix_param_camera_alignment\"] = \"/data3/shared/elastix_parameters/parameters_bfp_registration_euler.txt\"\n",
    "    end\n",
    "\n",
    "    \n",
    "    param[\"nonsynced_roi_val\"] = 4095\n",
    "\n",
    "    param_path[\"path_om_tmp\"] = joinpath(param_path[\"path_om_data\"], \"temp\"); # Path to a temporary directory on OpenMind to store data\n",
    "    \n",
    "    param[\"spacing_axi\"] = spacing_axi\n",
    "    param[\"spacing_lat\"] = spacing_lat\n",
    "    param[\"n_z\"] = 80\n",
    "    param[\"z_range\"] = 4:80\n",
    "\n",
    "    \n",
    "    ### crop\n",
    "    param[\"crop_threshold_size\"] = 20\n",
    "    param[\"crop_threshold_intensity\"] = 7.\n",
    "\n",
    "    ### UNet\n",
    "    param[\"seg_threshold_unet\"] = 0.5 # The UNet output confidence threshold for a pixel to be counted as a neuron.\n",
    "    param[\"seg_min_neuron_size\"] = 7 # Neurons with fewer than this many voxels will be discarded.\n",
    "    param[\"seg_threshold_watershed\"] = [0.7, 0.8, 0.9] #= The image is re-segmented at these thresholds,\n",
    "        and checked for neurons that were split - these neurons will be segmented by watershed.=#\n",
    "    param[\"seg_watershed_min_neuron_sizes\"] = [5,4,4] #= When the image is re-segmented, neurons smaller\n",
    "        than the size for the corresponding threshold will be discarded.=#\n",
    "    param[\"instance_seg_num_batches\"] = 5 # number of batches of data to run simultaneously\n",
    "        # each batch = number of threads. Lower number = less memory used, but more chance of bad parity\n",
    "\n",
    "    ### Registration graph\n",
    "    param[\"degree\"] = 10 # degree of registration graph\n",
    "    param[\"degree_dataset\"] = 2 # degree of inter-dataset registration graph\n",
    "\n",
    "    ### Head finder\n",
    "    param[\"head_threshold\"] = 0.5 # head detection UNet threshold\n",
    "    param[\"head_max_distance\"] = [20,35,35] #= distance thresholds for the blobification of the worm\n",
    "        that finds the head location=#\n",
    "    param[\"head_err_threshold\"] = 50 # sets a warning flag in the blobification\n",
    "    param[\"head_vc_err_threshold\"] = 150 # sets a warning flag in the blobification\n",
    "    param[\"head_edge_err_threshold\"] = 1 # sets a warning flag in the blobification\n",
    "\n",
    "    ### Worm curve finder\n",
    "    param[\"worm_curve_n_pts\"] = 14 # number of points in worm curve detector\n",
    "    param[\"worm_curve_head_idx\"] = 4 #= index of \"head\" point - ideally near the front of the\n",
    "        brain but not on the tip of the nose=#\n",
    "    param[\"worm_curve_tail_idx\"] = 11 #= index of tail\" point - ideally near the back of the\n",
    "        brain but not on the ventral cord=#\n",
    "    param[\"worm_curve_downscale\"] = 2 # binning factor for worm curve detector\n",
    "\n",
    "    ### Registration parameters\n",
    "    param[\"reg_n_resolution_activity_marker\"] = [3]\n",
    "\n",
    "\n",
    "    ### Quality control and heuristic parameters\n",
    "    param[\"smeared_neuron_threshold\"] = 20000 # ROIs that get smeared out to more than this many pixels due to registration will be deleted\n",
    "    param[\"max_centroid_dist\"] = 10 # maximum centroid distance post-registration \n",
    "    param[\"quality_metric\"] = \"NCC\" # registration quality metric\n",
    "    param[\"regularization_key\"] = \"nonrigid_penalty\"\n",
    "    \n",
    "\n",
    "    param[\"matrix_self_weight\"] = 1.0 # weight of the diagonal of registration map matrix\n",
    "    param[\"min_cluster_weight\"] = 1e-6 # minimum weight\n",
    "    param[\"overlap_weight\"] = 1.0 # weight for ROI overlaps\n",
    "    param[\"centroid_weight\"] = 1.0 # weight for centroid distance between ROIs\n",
    "    param[\"activity_diff_weight\"] = 3.0 # weight for red activity difference\n",
    "    param[\"q_weight\"] = 25.0 # weight for NCC of registration\n",
    "    param[\"regularization_weight\"] = 1.0 # weight of DDF regularization penalty\n",
    "    param[\"displacement_weight\"] = 2.0 # weight of displacement heuristic (ROIs that move farther are less likely to be correct)\n",
    "\n",
    "    ### Clustering parameters\n",
    "    param[\"cluster_height_thresh\"] = -0.0001 # clustering threshold for multiple clusters will be merged together. Reasonable range -0.3 to 0\n",
    "    param[\"cluster_overlap_thresh\"] = 0.05 # tolerance for a cluster to have multiple ROIs from the same frame. Reasonable range 0 to 0.2\n",
    "    \n",
    "    param[\"frac_detections_threshold\"] = 0.5 # fraction of time points that an ROI candidates must be detected in\n",
    "    \n",
    "\n",
    "    ### Deconvolution parameters\n",
    "    param[\"gcamp_decay_response\"] = 0.52; # GCaMP decay time, in seconds\n",
    "    \n",
    "    param[\"duration\"] = Dates.Time(4,0,0)\n",
    "    param[\"duration_julia\"] = \"2-0\"\n",
    "    param[\"partition_sbatch_script\"] = \"normal\"\n",
    "    param[\"memory\"] = 1\n",
    "    param[\"cpu_per_task\"] = 16\n",
    "    param[\"ch_marker\"] = ch_red\n",
    "    param[\"ch_activity\"] = ch_bluegreen\n",
    "    param[\"list_ch\"] = unique([param[\"ch_marker\"], param[\"ch_activity\"]])\n",
    "    param[\"email\"] = nothing\n",
    "    param[\"use_sbatch\"] = true\n",
    "    param[\"server\"] = \"openmind7.mit.edu\"\n",
    "    param[\"server_dtn\"] = \"openmind-dtn.mit.edu\"\n",
    "    param[\"job_name\"] = \"elx\"\n",
    "    param[\"job_name_activity_marker\"] = \"elx_ch12\"\n",
    "    param[\"job_name_marker_activity\"] = \"elx_ch21\"\n",
    "    param[\"array_size\"] = 450\n",
    "    param[\"partition\"] = \"use-everything\"\n",
    "    param[\"elx_wait_delay\"] = 3600\n",
    "    param[\"lock_wait\"] = 0.5\n",
    "    param[\"user\"] = om_user;\n",
    "    \n",
    "    param[\"FLIR_FPS\"] = 20.0; # FPS of NIR camera\n",
    "    param[\"bad_tracking\"] = []; # points to delete (NIR timeframe) due to bad tracking\n",
    "    param[\"n_rec\"] = 1 # number of Illumination Sequence module recordings (.nd2) in the HDF5 file\n",
    "\n",
    "    ### Spline parameters\n",
    "    param[\"num_center_pts\"] = 1000 # number of points in raw worm spline\n",
    "    param[\"segment_len\"] = 7 # length of raw spline per segment of distance-corrected spline\n",
    "    param[\"img_label_size\"] = (480,360) # size of UNet input image\n",
    "\n",
    "    ### Spline self-intersect correction parameters\n",
    "    param[\"med_axis_shorten_threshold\"] = 14 # if the medial axis shortens by at least this amount, trigger self-intersect correction\n",
    "    param[\"nose_confidence_threshold\"] = 0.99 # threshold for UNet's confidence of nose location for it to be used to crop medial axis\n",
    "    param[\"nose_crop_threshold\"] = 20 # maximum number of points in medial axis that can be cropped to the nose\n",
    "    param[\"med_axis_self_dist_threshold\"] = 40 # proximity of far-away medial axis points that will trigger self-intersect correction\n",
    "    param[\"loop_dist_threshold\"] = 60 # distance between medial axis points beyond which collisions/proximity trigger self-intersect correction\n",
    "    param[\"max_med_axis_delta\"] = Inf # change in pixels from points in one time point's medial axis to the next to trigger self-intersect correction\n",
    "    param[\"trim_head_tail\"] = 15; # amount to trim head and tail of worm boundary to allow motion of worm\n",
    "    param[\"boundary_thickness\"] = 5; # thickness of worm boundary\n",
    "    param[\"close_pts_threshold\"] = 30; # minimum distance on spline for boundary to be enforced\n",
    "    param[\"worm_thickness_pad\"] = 3 # gap between worm and worm boundary\n",
    "    param[\"min_len_percent\"] = 90; # lower percentile of non-self-intersect time points to be included in worm thickness computation\n",
    "    param[\"max_len_percent\"] = 98; # upper percentile of non-self-intersect time points to be included in worm thickness computation\n",
    "    \n",
    "    ### Body angle parameters\n",
    "    param[\"body_angle_pos_lag\"] = 2; # how far to enforce angle-continuity along a time point's spline\n",
    "    param[\"body_angle_t_lag\"] = 40; # how far to enforce angle-continuity along a particular spline-angle across time points\n",
    "    param[\"max_pt\"] = 31; # crop the spline at this location\n",
    "\n",
    "    param[\"nose_pts\"] = [1,2,3]; # points in spline corresponding to nose angle\n",
    "    param[\"head_pts\"] = [1,5,8]; # points in spline corresponding to head angle\n",
    "    param[\"seg_range\"] = param[\"head_pts\"][3]:param[\"max_pt\"]; # range of points for computing worm centroid\n",
    "\n",
    "    ### Reversal parameters\n",
    "    param[\"rev_len_thresh\"] = 2; # length threshold for reversal events\n",
    "    param[\"rev_v_thresh\"] = -0.005; # velocity threshold for reversal events\n",
    "\n",
    "    ### Angular velocity parameters\n",
    "    param[\"filt_len_angvel\"] = 150\n",
    "\n",
    "    ### Pumping parameters\n",
    "    param[\"filt_len_pumping\"] = 40\n",
    "\n",
    "    ### Other parameters\n",
    "    param[\"num_lag\"] = 1;  # number of NIR time points to smooth velocity and other variables with SG filter\n",
    "    param[\"v_stage_m_filt\"] = 10; # length of NIR time point window for position filtering\n",
    "    param[\"v_stage_Î»_filt\"] = 250.0; # parameter for position filtering\n",
    "    \n",
    "    param[\"num_eigenworm\"] = 5 # number of eigenworms to compute\n",
    "\n",
    "    # behavior variables for MI and neuron prediction GLM in addition to eigenworm and body angle\n",
    "    param[\"vars\"] = [\"velocity_stage\", \"worm_angle\", \"head_angle\", \"nose_angle\", \"angular_velocity\", \"worm_curvature\"]\n",
    "\n",
    "    # behavior variables for multi-dataset concatenation\n",
    "    param[\"concat_vars\"] = [\"angular_velocity\", \"worm_angle\", \"head_angle\", \"nose_angle\", \"speed_stage\", \"worm_curvature\",\n",
    "            \"ventral_worm_curvature\", \"nose_curling\", \"velocity_stage\",\n",
    "            \"zeroed_x_confocal\", \"zeroed_y_confocal\", \"body_angle\", \"body_angle_all\", \"body_angle_absolute\", \"rev_times\"]\n",
    "    param[\"t_concat_vars\"] = [\"all_rev\"];\n",
    "    param[\"nir_concat_vars\"] = [\"nir_velocity_stage\", \"nir_head_angle\", \"nir_body_angle\", \"nir_body_angle_all\",\n",
    "            \"nir_body_angle_absolute\", \"nir_nose_curling\",\n",
    "            \"zeroed_x\", \"zeroed_y\"]\n",
    "\n",
    "    param[\"beta_values\"] = [Int32(round(1.6^x)) for x=0:9] # inverse values of L1 norm penalty to use for neuron prediction GLM\n",
    "    param[\"t_thresh_vals_base\"] = -100:50:100; # thresholds between training and validation data to use for neuron prediction GLM\n",
    "\n",
    "    param[\"rev_neuron_thresh\"] = 0.5 # goodness of fit required to classify a neuron as a reversal neuron\n",
    "    param[\"type1_thresh\"] = 2; # maximum reversal length threshold for a type-1 reversal neuron\n",
    "\n",
    "    param[\"fwd_neuron_thresh\"] = 0.75; # goodness of fit required to classify a neuron as a forward neuron\n",
    "    param[\"turning_neuron_thresh\"] = 0.75; # goodness of fit required to classify a neuron as a turning neuron\n",
    "    \n",
    "    \n",
    "    \n",
    "    param_path[\"path_param_path\"] = joinpath(path_root_process, \"param_path.jld2\")\n",
    "\n",
    "    param_path[\"path_nd2\"] = joinpath(path_raw_data, exp_prefix*\".nd2\")\n",
    "    \n",
    "    if dataset in datasets_freely_moving\n",
    "        param_path[\"path_h5\"] = joinpath(path_raw_data, exp_prefix*\".h5\")\n",
    "    end\n",
    "    path_dir_nd2, name_nd2 = splitdir(param_path[\"path_nd2\"])\n",
    "    param_path[\"img_prefix\"] = splitext(name_nd2)[1]\n",
    "    path_root_raw = path_dir_nd2\n",
    "    list_ch = param[\"list_ch\"]\n",
    "\n",
    "    dir_nrrd = \"NRRD\"\n",
    "    dir_MIP = \"MIP\"\n",
    "    dir_nrrd_shearcorrect = \"NRRD_shearcorrect\"\n",
    "    dir_MIP_shearcorrect = \"MIP_shearcorrect\"\n",
    "    dir_nrrd_crop = \"NRRD_cropped\"\n",
    "    dir_MIP_crop = \"MIP_cropped\"\n",
    "    dir_nrrd_filt = \"NRRD_filtered\"\n",
    "    dir_MIP_filt = \"MIP_filtered\"\n",
    "\n",
    "    dir_roi = \"img_roi\"\n",
    "    dir_roi_watershed = \"img_roi_watershed\"\n",
    "    dir_roi_watershed_uncropped = \"img_roi_watershed_uncropped\"\n",
    "    dir_marker_signal = \"ch4_signal\"\n",
    "    dir_centroid = \"centroids\"\n",
    "    dir_unet_data = \"unet_data\"\n",
    "\n",
    "    dir_worm_curve = \"worm_curve\"\n",
    "    dir_reg = \"Registered\"\n",
    "    dir_reg_activity_marker = \"Registered_ch1to2\"\n",
    "    dir_reg_marker_activity = \"Registered_ch2to1\"\n",
    "\n",
    "    dir_transformed = \"img_roi_transformed\"\n",
    "    dir_transformed_activity_marker = \"NRRD_activity_transformed\"\n",
    "    dir_activity_signal = \"gcamp_activity_transformed\"\n",
    "    dir_cmd = \"elx_commands\"\n",
    "    dir_cmd_am = \"elx_commands_ch1to2\"\n",
    "    dir_cmd_ma = \"elx_commands_ch2to1\"\n",
    "    dir_cmd_array = \"elx_commands_array\"\n",
    "    dir_log = \"log\"\n",
    "\n",
    "    dir_roi_candidates = \"roi_candidates\"\n",
    "\n",
    "    txt_file_extension = \".txt\"\n",
    "    name_head_pos = \"head_pos\"\n",
    "    name_elastix_difficulty = \"elastix_difficulty\"\n",
    "    name_reg_prob = \"registration_problems\"\n",
    "    name_reg_quality = \"registration_quality\"\n",
    "    name_qdict = \"q_dict\"\n",
    "    name_best_reg = \"best_reg\"\n",
    "    name_roi_overlap = \"roi_overlap\"\n",
    "    name_roi_activity_diff = \"roi_activity_diff\"\n",
    "    name_label_map = \"label_map\"\n",
    "    name_inv_map = \"inv_map\"\n",
    "    name_data_dict = \"data_dict.jld2\"\n",
    "    name_param = \"param.jld2\"\n",
    "    name_param_path = \"param_path.jld2\"\n",
    "    name_error_dict = \"error_dict.jld2\"\n",
    "\n",
    "    param_path[\"path_root_process\"] = path_root_process\n",
    "    param_path[\"name_head_rotate_logfile\"] = \"headrotate.log\"\n",
    "    param_path[\"name_transform_activity_marker\"] = \"TransformParameters.0.txt\"\n",
    "    param_path[\"name_transform_activity_marker_avg\"] = \"TransformParameters.0_avg.txt\"\n",
    "    param_path[\"name_transform_activity_marker_roi\"] = \"TransformParameters.0_roi.txt\"\n",
    "    param_path[\"key_transform_parameters\"] = \"TransformParameters\"\n",
    "    \n",
    "    if !(dataset in datasets_freely_moving)\n",
    "        param_path[\"path_dir_reg_activity\"] = joinpath(param_path[\"path_root_process\"], \"Registered_G\")\n",
    "        param_path[\"path_om_reg_activity\"] = joinpath(param_path[\"path_om_data\"], \"Registered_G\")\n",
    "        param_path[\"path_dir_cmd_activity\"] = joinpath(param_path[\"path_root_process\"], \"elx_commands_G\")\n",
    "        param_path[\"path_om_cmd_activity\"] = joinpath(param_path[\"path_om_data\"], \"elx_commands_G\")\n",
    "        param[\"job_name_activity\"] = \"elx_ch1\"\n",
    "        param_path[\"path_nrrd_avg\"] = joinpath.(param_path[\"path_root_process\"], [\"avg_ch1.nrrd\", \"avg_ch2.nrrd\"])\n",
    "        param_path[\"path_nrrd_avg_ch1toch2\"] = joinpath(param_path[\"path_root_process\"], \"avg_ch1toch2\")\n",
    "        param_path[\"path_nrrd_avg_ch1toch2_reg\"] = joinpath(param_path[\"path_root_process\"], \"avg_ch1toch2_reg\")\n",
    "        param_path[\"nrrd_avg_res\"] = \"result.2.R0.nrrd\"\n",
    "        param_path[\"parameter_files_local\"] = [joinpath(\"$(data_dir)/shared/elastix_parameters\", \"parameters_immobilized_bspline_turbo_v2.txt\")]\n",
    "        param_path[\"path_dir_reg_neuropal\"] = joinpath(param_path[\"path_root_process\"], \"Registered_to_$(dataset_immobilized_central)\")\n",
    "        param_path[\"euler_head_params\"] = joinpath(param_path[\"path_dir_reg_neuropal\"], \"euler.txt\")\n",
    "        param_path[\"path_nrrd_avg_translate\"] = joinpath.(param_path[\"path_root_process\"], [\"avg_ch1_translate.nrrd\", \"avg_ch2_translate.nrrd\"])\n",
    "        param_path[\"path_nrrd_avg_ch1toch2_translate\"] = joinpath(param_path[\"path_root_process\"], \"avg_ch1toch2_translate.nrrd\")\n",
    "    end\n",
    "\n",
    "\n",
    "    param_path[\"path_dir_unet_data\"], param_path[\"path_dir_nrrd\"], param_path[\"path_dir_MIP\"], \n",
    "        param_path[\"path_dir_nrrd_shearcorrect\"], param_path[\"path_dir_MIP_shearcorrect\"], \n",
    "        param_path[\"path_dir_nrrd_crop\"],\n",
    "        param_path[\"path_dir_nrrd_filt\"], param_path[\"path_dir_MIP_crop\"], param_path[\"path_dir_MIP_filt\"] = \n",
    "            joinpath.(path_root_process, [dir_unet_data, dir_nrrd, dir_MIP, dir_nrrd_shearcorrect, dir_MIP_shearcorrect, dir_nrrd_crop, dir_nrrd_filt, dir_MIP_crop, dir_MIP_filt])\n",
    "\n",
    "    param_path[\"path_dir_transformed\"], param_path[\"path_dir_transformed_activity_marker\"], param_path[\"path_dir_activity_signal\"] =\n",
    "        joinpath.(path_root_process, [dir_transformed, dir_transformed_activity_marker, dir_activity_signal])\n",
    "\n",
    "    param_path[\"path_dir_roi\"], param_path[\"path_dir_roi_watershed\"], param_path[\"path_dir_roi_watershed_uncropped\"], \n",
    "        param_path[\"path_dir_marker_signal\"], param_path[\"path_dir_centroid\"], param_path[\"path_dir_unet_data\"] =\n",
    "            joinpath.(path_root_process, [dir_roi, dir_roi_watershed, dir_roi_watershed_uncropped, dir_marker_signal,\n",
    "                dir_centroid, dir_unet_data])\n",
    "\n",
    "    param_path[\"path_dir_worm_curve\"], param_path[\"path_dir_reg\"], param_path[\"path_dir_reg_activity_marker\"], \n",
    "        param_path[\"path_dir_reg_marker_activity\"],\n",
    "        param_path[\"path_roi_candidates\"], param_path[\"path_dir_cmd\"], param_path[\"path_dir_cmd_am\"], param_path[\"path_dir_cmd_ma\"],\n",
    "        param_path[\"path_dir_cmd_array\"], param_path[\"path_data_dict\"], \n",
    "        param_path[\"path_param\"], param_path[\"path_param_path\"], param_path[\"path_error_dict\"] =\n",
    "            joinpath.(path_root_process,\n",
    "                [dir_worm_curve, dir_reg, dir_reg_activity_marker, dir_reg_marker_activity, dir_roi_candidates, dir_cmd, \n",
    "                    dir_cmd_am, dir_cmd_ma, dir_cmd_array, name_data_dict, name_param,\n",
    "                    name_param_path, name_error_dict])\n",
    "\n",
    "    param_path[\"path_om_nrrd_filt\"], param_path[\"path_om_nrrd\"], param_path[\"path_om_reg\"], \n",
    "        param_path[\"path_om_reg_activity_marker\"], param_path[\"path_om_reg_marker_activity\"],\n",
    "        param_path[\"path_om_log\"] = joinpath.(param_path[\"path_om_data\"],\n",
    "            [dir_nrrd_filt, dir_nrrd, dir_reg, dir_reg_activity_marker, dir_reg_marker_activity, dir_log])\n",
    "\n",
    "    param_path[\"path_om_cmd\"], param_path[\"path_om_cmd_am\"], param_path[\"path_om_cmd_ma\"], \n",
    "        param_path[\"path_om_cmd_array\"] = joinpath.(param_path[\"path_om_scripts\"], \n",
    "            [dir_cmd, dir_cmd_am, dir_cmd_ma, dir_cmd_array])\n",
    "\n",
    "    param_path[\"path_head_pos\"], param_path[\"path_elastix_difficulty\"], param_path[\"path_reg_prob\"], \n",
    "        param_path[\"path_qdict\"], param_path[\"path_best_reg\"], param_path[\"path_roi_overlap\"], \n",
    "        param_path[\"path_roi_activity_diff\"], param_path[\"path_reg_quality\"], param_path[\"path_label_map\"], param_path[\"path_inv_map\"] = joinpath.(path_root_process, \n",
    "            [name_head_pos, name_elastix_difficulty, name_reg_prob, name_qdict, name_best_reg,\n",
    "            name_roi_overlap, name_roi_activity_diff, name_reg_quality, name_label_map,\n",
    "            name_inv_map] .* txt_file_extension)\n",
    "    \n",
    "\n",
    "    param_path[\"path_dir_mask\"] = nothing\n",
    "    param_path[\"path_om_mask\"] = nothing\n",
    "\n",
    "    param_path[\"parameter_files\"] = [param_path[\"path_om_euler_param\"], param_path[\"path_om_affine_param\"], param_path[\"path_om_bspline_param\"]]\n",
    "    param_path[\"parameter_files_activity_marker\"] = [param_path[\"path_om_euler_am_param\"]]\n",
    "\n",
    "    create_dir(param_path[\"path_root_process\"])\n",
    "    if !(dataset in datasets_freely_moving)\n",
    "        create_dir(param_path[\"path_nrrd_avg_ch1toch2\"])\n",
    "        create_dir(param_path[\"path_dir_reg_neuropal\"])\n",
    "    end\n",
    "\n",
    "    create_dir(param_path[\"path_dir_transformed_activity_marker\"])\n",
    "    create_dir(param_path[\"path_dir_transformed\"])\n",
    "    create_dir(param_path[\"path_roi_candidates\"])\n",
    "    create_dir(param_path[\"path_dir_activity_signal\"])\n",
    "    create_dir(param_path[\"path_dir_marker_signal\"])\n",
    "    create_dir(param_path[\"path_dir_reg\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to keep the default batch size, you can change it here. The main relevant factor is GPU VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[dataset_central][\"deepreg_batch_size\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this code to overwrite previous dictionaries.\n",
    "for dataset in keys(datasets)\n",
    "    if \"get_basename\" in keys(param_paths[dataset])\n",
    "        delete!(param_paths[dataset], \"get_basename\")\n",
    "    end\n",
    "\n",
    "    param_path = param_paths[dataset]\n",
    "    param = params[dataset]\n",
    "    JLD2.@save(param_path[\"path_param_path\"], param_path)\n",
    "    add_get_basename!(param_path)\n",
    "    JLD2.@save(param_path[\"path_param\"], param)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `param[\"t_range\"]` to be a list of datasets (numerically, by index) that you want to analyze. We use all available datasets here - even the one with incorrect human labels, as this unsupervised algorithm does not care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in keys(datasets)\n",
    "    if dataset in datasets_freely_moving\n",
    "        path_root_process = path_root_process_freelymoving\n",
    "    else\n",
    "        path_root_process = joinpath(path_root_process_immobilized, datasets[dataset])\n",
    "    end\n",
    "    path_param_path = joinpath(path_root_process, \"param_path.jld2\")\n",
    "    \n",
    "    if isfile(path_param_path)\n",
    "        f = JLD2.jldopen(path_param_path)\n",
    "        param_paths[dataset] = f[\"param_path\"]\n",
    "        close(f)\n",
    "    end\n",
    "    param_path = param_paths[dataset]\n",
    "\n",
    "    change_rootpath!(param_path, path_root_process)\n",
    "\n",
    "    if isfile(param_path[\"path_param\"])\n",
    "        f = JLD2.jldopen(param_path[\"path_param\"])\n",
    "        params[dataset] = f[\"param\"]\n",
    "        close(f)\n",
    "    end\n",
    "    \n",
    "    param = params[dataset]\n",
    "\n",
    "    add_get_basename!(param_path)\n",
    "    \n",
    "    if isfile(param_path[\"path_data_dict\"])\n",
    "        f = JLD2.jldopen(param_path[\"path_data_dict\"])\n",
    "        data_dicts[dataset] = f[\"data_dict\"]\n",
    "        close(f)\n",
    "    else\n",
    "        data_dicts[dataset] = Dict()\n",
    "    end\n",
    "\n",
    "    data_dict = data_dicts[dataset]\n",
    "\n",
    "    param[\"t_range\"] = [t for t in 1:102] # change this line of code as needed\n",
    "\n",
    "    error_dicts[dataset] = Dict()\n",
    "end\n",
    "\n",
    "for dataset in datasets_register\n",
    "    path = joinpath(param_paths[dataset_central][\"path_root_process\"], \"$(dataset)_registered_data_dict.jld2\")\n",
    "    if isfile(path)\n",
    "        f = JLD2.jldopen(path)\n",
    "        data_dicts[\"$(dataset)_to_central\"] = f[\"data_dict\"]\n",
    "        close(f)\n",
    "    else\n",
    "        data_dicts[\"$(dataset)_to_central\"] = Dict()\n",
    "    end\n",
    "    error_dicts[\"$(dataset)_to_central\"] = Dict()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let\n",
    "#     f = JLD2.jldopen(\"/scratch/adam/multicolor_deepreg_test_3/euler_parameters.jld2\")\n",
    "#     data_dicts[dataset_central][\"euler_parameters\"] = f[\"euler_parameters\"]\n",
    "#     close(f)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify which animals to use\n",
    "\n",
    "Each dataset corresponds to one animal. If you want to keep track of which datasets were used in training/validation/testing of this notebook's version of CellDiscoveryNet, set `datasets_train`, `datasets_val`, and `datasets_test` here appropriately.\n",
    "\n",
    "`datasets_` should contain all animals you wish to analyze (train, val, and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_prj_neuropal = [\"2022-07-15-06\", \"2022-07-15-12\", \"2022-07-20-01\", \"2022-07-26-01\", \"2022-08-02-01\", \"2023-01-23-08\", \"2023-01-23-15\", \"2023-01-23-21\", \"2023-01-19-08\", \"2023-01-19-22\", \"2023-01-09-28\", \"2023-01-17-01\", \"2023-01-19-15\", \"2023-01-23-01\", \"2023-03-07-01\", \"2022-12-21-06\", \"2023-01-05-18\", \"2023-01-06-01\", \"2023-01-06-08\", \"2023-01-09-08\", \"2023-01-09-15\", \"2023-01-09-22\", \"2023-01-10-07\", \"2023-01-10-14\", \"2023-01-13-07\", \"2023-01-16-01\", \"2023-01-16-08\", \"2023-01-16-15\", \"2023-01-16-22\", \"2023-01-17-07\", \"2023-01-17-14\", \"2023-01-18-01\"]\n",
    "datasets_prj_rim = [\"2023-06-09-01\", \"2023-07-28-04\", \"2023-06-24-02\", \"2023-07-07-11\", \"2023-08-07-01\", \"2023-06-24-11\", \"2023-07-07-18\", \"2023-08-18-11\", \"2023-06-24-28\", \"2023-07-11-02\", \"2023-08-22-08\", \"2023-07-12-01\", \"2023-07-01-09\", \"2023-07-13-01\", \"2023-06-09-10\", \"2023-07-07-01\", \"2023-08-07-16\", \"2023-08-22-01\", \"2023-08-23-23\", \"2023-08-25-02\", \"2023-09-15-01\", \"2023-09-15-08\", \"2023-08-18-18\", \"2023-08-19-01\", \"2023-08-23-09\", \"2023-08-25-09\", \"2023-09-01-01\", \"2023-08-31-03\", \"2023-07-01-01\", \"2023-07-01-23\"]\n",
    "\n",
    "datasets_prj_aversion = [\"2023-03-30-01\", \"2023-06-29-01\", \"2023-06-29-13\", \"2023-07-14-08\", \"2023-07-14-14\", \"2023-07-27-01\", \"2023-08-08-07\", \"2023-08-14-01\", \"2023-08-16-01\", \"2023-08-21-01\", \"2023-09-07-01\", \"2023-09-14-01\", \"2023-08-15-01\", \"2023-10-05-01\", \"2023-06-23-08\", \"2023-12-11-01\", \"2023-06-21-01\"]\n",
    "datasets_prj_5ht = [\"2022-07-26-31\", \"2022-07-26-38\", \"2022-07-27-31\", \"2022-07-27-38\", \"2022-07-27-45\", \"2022-08-02-31\", \"2022-08-02-38\", \"2022-08-03-31\"]\n",
    "datasets_prj_starvation = [\"2023-05-25-08\", \"2023-05-26-08\", \"2023-06-05-10\", \"2023-06-05-17\", \"2023-07-24-27\", \"2023-09-27-14\", \"2023-05-25-01\", \"2023-05-26-01\", \"2023-07-24-12\", \"2023-07-24-20\", \"2023-09-12-01\", \"2023-09-19-01\", \"2023-09-29-19\", \"2023-10-09-01\", \"2023-09-13-02\"]\n",
    "\n",
    "# append all datasets togther\n",
    "datasets_ = []\n",
    "append!(datasets_, datasets_prj_neuropal)\n",
    "append!(datasets_, datasets_prj_rim)\n",
    "append!(datasets_, datasets_prj_aversion)\n",
    "append!(datasets_, datasets_prj_5ht)\n",
    "append!(datasets_, datasets_prj_starvation)\n",
    "\n",
    "datasets_val = [\"2023-06-24-02\", \"2023-08-07-01\", \"2023-08-19-01\", # RIM datasets\n",
    "                \"2022-07-26-01\", \"2023-01-23-21\", \"2023-01-23-01\", # NeuroPAL datasets\n",
    "                \"2023-07-14-08\", # Aversion datasets\n",
    "                \"2022-08-02-31\", # 5-HT datasets\n",
    "                \"2023-07-24-27\", \"2023-07-24-20\"] # Starvation datasets\n",
    "datasets_test = [\"2023-08-22-01\", \"2023-07-07-18\", \"2023-07-01-23\",  # RIM datasets\n",
    "                 \"2023-01-06-01\", \"2023-01-10-07\", \"2023-01-17-07\", # Neuropal datasets\n",
    "                 \"2023-08-21-01\", \"2023-06-23-08\", # Aversion datasets\n",
    "                 \"2022-07-27-38\", # 5-HT datasets\n",
    "                 \"2023-10-09-01\", \"2023-09-13-02\" # Starvation datasets\n",
    "                 ]\n",
    "datasets_train = [dataset for dataset in datasets_ if !(dataset in datasets_val) && !(dataset in datasets_test)]\n",
    "datasets_ = deepcopy(datasets_train)\n",
    "append!(datasets_, datasets_val)\n",
    "append!(datasets_, datasets_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also speficy which side the worm was laying on here. Note that you should have already rotated the worm to lie on the same side before running this notebook, but there are still optical differences between the two sides. Loading the values here allows certain diagnostic code blocks to run that can check whether there is an issue registering one orientation to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Î¸h_pos_is_ventral = Dict(\n",
    "    \"2023-06-09-01\"=> true,\n",
    "    \"2023-06-24-02\"=> false,\n",
    "    \"2023-06-24-28\"=> true,\n",
    "    \"2023-07-01-01\"=> true,\n",
    "    \"2023-07-01-09\"=> false,\n",
    "    \"2023-07-07-01\"=> false,\n",
    "    \"2023-07-07-18\"=> true,\n",
    "    \"2023-07-11-02\"=> false,\n",
    "    \"2023-07-28-04\"=> true,\n",
    "    \"2023-07-07-11\"=> false,\n",
    "    \"2023-07-12-01\"=> true,\n",
    "    \"2023-08-07-01\"=> false,\n",
    "    \"2023-08-22-08\"=> true,\n",
    "    \"2023-08-18-11\"=> false,\n",
    "    \"2023-06-24-11\"=> true,\n",
    "    \"2023-07-13-01\"=> false,\n",
    "    \"2023-08-07-16\"=> false,\n",
    "    \"2023-06-09-10\"=> true,\n",
    "    \"2023-08-22-01\"=> false,\n",
    "    \"2023-08-23-23\"=> false,\n",
    "    \"2023-08-25-02\"=> true,\n",
    "    \"2023-09-15-01\"=> true,\n",
    "    \"2023-09-15-08\"=> true,\n",
    "    \"2023-08-18-18\"=> false,\n",
    "    \"2023-08-19-01\"=> true,\n",
    "    \"2023-08-23-09\"=> true,\n",
    "    \"2023-09-02-10\"=> true,\n",
    "    \"2023-08-25-09\"=> false,\n",
    "    \"2023-09-01-01\"=> true,\n",
    "    \"2023-08-31-03\"=> false,\n",
    "    \"2023-07-01-23\"=> false,\n",
    "    \"2021-05-26-07\"=> true,\n",
    "    \"2021-06-11-01\"=> true,\n",
    "    \"2021-08-04-06\"=> false,\n",
    "    \"2021-08-17-01\"=> true,\n",
    "    \"2021-08-18-01\"=> true,\n",
    "    \"2021-09-06-09\"=> true,\n",
    "    \"2021-09-14-01\"=> true,\n",
    "    \"2021-09-14-05\"=> false,\n",
    "    \"2021-09-22-05\"=> true,\n",
    "    \"2021-09-23-01\"=> true,\n",
    "    \"2021-09-30-01\"=> false,\n",
    "    \"2021-10-26-01\"=> false,\n",
    "    \"2021-11-12-01\"=> true,\n",
    "    \"2021-11-12-05\"=> false,\n",
    "    \"2022-01-07-03\"=> true, # NOT ACTUALLY COMPUTED\n",
    "    \"2022-01-09-01\"=> false,\n",
    "    \"2022-01-17-01\"=> false,\n",
    "    \"2022-01-23-01\"=> true,\n",
    "    \"2022-01-26-01\"=> true,\n",
    "    \"2022-01-27-01\"=> false,\n",
    "    \"2022-01-27-04\"=> true,\n",
    "    \"2022-02-08-01\"=> true,\n",
    "    \"2022-02-08-04\"=> false,\n",
    "    \"2022-02-16-01\"=> false,\n",
    "    \"2022-02-16-04\"=> true,\n",
    "    \"2022-03-15-04\"=> true,\n",
    "    \"2022-03-16-01\"=> true, # NOT ACTUALLY COMPUTED\n",
    "    \"2022-03-16-02\"=> true, # NOT ACTUALLY COMPUTED\n",
    "    \"2022-03-22-01\"=> true,\n",
    "    \"2022-04-05-01\"=> true,\n",
    "    \"2022-04-12-04\"=> true,\n",
    "    \"2022-04-14-04\"=> true,\n",
    "    \"2022-04-18-04\"=> false,\n",
    "    \"2022-05-17-01\"=> false,\n",
    "    \"2022-05-17-06\"=> false,\n",
    "    \"2022-05-25-02\"=> false,\n",
    "    \"2022-06-14-01\"=> true,\n",
    "    \"2022-06-14-07\"=> true,\n",
    "    \"2022-06-14-13\"=> true,\n",
    "    \"2022-06-28-01\"=> true,\n",
    "    \"2022-06-28-07\"=> true,\n",
    "    \"2022-07-15-06\"=> true,\n",
    "    \"2022-07-15-12\"=> true,\n",
    "    \"2022-07-20-01\"=> true,\n",
    "    \"2022-07-26-01\"=> true,\n",
    "    \"2022-07-29-08\"=> true,\n",
    "    \"2022-08-02-01\"=> true,\n",
    "    \"2022-12-21-06\"=> true,\n",
    "    \"2023-01-05-01\"=> true,\n",
    "    \"2023-01-05-18\"=> true,\n",
    "    \"2023-01-06-01\"=> true,\n",
    "    \"2023-01-06-08\"=> true,\n",
    "    \"2023-01-06-15\"=> true,\n",
    "    \"2023-01-09-08\"=> true,\n",
    "    \"2023-01-09-15\"=> true,\n",
    "    \"2023-01-09-22\"=> true,\n",
    "    \"2023-01-09-28\"=> true,\n",
    "    \"2023-01-10-07\"=> true,\n",
    "    \"2023-01-10-14\"=> true,\n",
    "    \"2023-01-13-07\"=> true,\n",
    "    \"2023-01-16-01\"=> true,\n",
    "    \"2023-01-16-08\"=> true,\n",
    "    \"2023-01-16-15\"=> true,\n",
    "    \"2023-01-16-22\"=> true,\n",
    "    \"2023-01-17-01\"=> true,\n",
    "    \"2023-01-17-07\"=> true,\n",
    "    \"2023-01-17-14\"=> true,\n",
    "    \"2023-01-18-01\"=> true,\n",
    "    \"2023-01-19-01\"=> false,\n",
    "    \"2023-01-19-08\"=> true,\n",
    "    \"2023-01-19-15\"=> false,\n",
    "    \"2023-01-19-22\"=> true,\n",
    "    \"2023-01-23-01\"=> true,\n",
    "    \"2023-01-23-08\"=> true,\n",
    "    \"2023-01-23-15\"=> true,\n",
    "    \"2023-01-23-21\"=> true,\n",
    "    \"2023-03-07-01\"=> true,\n",
    "    \"2022-07-26-31\"=> true,\n",
    "    \"2022-07-26-38\"=> true,\n",
    "    \"2022-07-27-31\"=> true,\n",
    "    \"2022-07-27-38\"=> true,\n",
    "    \"2022-07-27-45\"=> true,\n",
    "    \"2022-08-02-31\"=> true,\n",
    "    \"2022-08-02-38\"=> true,\n",
    "    \"2022-08-03-31\"=> false,\n",
    "    \"2023-03-30-01\"=> true,\n",
    "    \"2023-06-21-01\"=> false,\n",
    "    \"2023-06-23-08\"=> true,\n",
    "    \"2023-06-29-01\"=> false,\n",
    "    \"2023-06-29-13\"=> true,\n",
    "    \"2023-07-14-08\"=> true,\n",
    "    \"2023-07-14-14\"=> false,\n",
    "    \"2023-07-27-01\"=> true,\n",
    "    \"2023-07-27-08\"=> true,\n",
    "    \"2023-08-08-07\"=> false,\n",
    "    \"2023-08-14-01\"=> true,\n",
    "    \"2023-08-15-01\"=> false,\n",
    "    \"2023-08-16-01\"=> true,\n",
    "    \"2023-08-21-01\"=> true,\n",
    "    \"2023-09-07-01\"=> false,\n",
    "    \"2023-09-14-01\"=> true,\n",
    "    \"2023-09-25-01\"=> true,\n",
    "    \"2023-10-05-01\"=> false,\n",
    "    \"2023-12-11-01\"=> true,\n",
    "    \"2023-05-25-08\"=> false,\n",
    "    \"2023-05-26-08\"=> false,\n",
    "    \"2023-06-05-10\"=> true,\n",
    "    \"2023-06-05-17\"=> false,\n",
    "    \"2023-07-24-27\"=> true,\n",
    "    \"2023-09-27-14\"=> false,\n",
    "    \"2023-05-25-01\"=> false,\n",
    "    \"2023-05-26-01\"=> false,\n",
    "    \"2023-05-30-14\"=> false,\n",
    "    \"2023-07-24-12\"=> false,\n",
    "    \"2023-07-24-20\"=> false,\n",
    "    \"2023-09-12-01\"=> false,\n",
    "    \"2023-09-19-01\"=> false,\n",
    "    \"2023-09-29-19\"=> false,\n",
    "    \"2023-10-09-01\"=> false,\n",
    "    \"2023-10-09-07\"=> false,\n",
    "    \"2023-09-13-02\"=> false\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = root_path_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up registration graph\n",
    "\n",
    "We define the registration graph to be the complete graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"registration_problems\"] = []\n",
    "for i in 1:length(datasets_)\n",
    "    for j in i+1:length(datasets_)\n",
    "        push!(data_dicts[dataset_central][\"registration_problems\"], (i,j))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CellDiscoveryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_process = addprocs(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere workers() begin\n",
    "    # ENV[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "    using ImageDataIO\n",
    "    using PyCall\n",
    "    using NRRDIO\n",
    "    using Statistics\n",
    "    using ImageRegistration\n",
    "    using FlavellBase\n",
    "    using ProgressMeter\n",
    "    using MultivariateStats\n",
    "    using HDF5\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eval @everywhere param_paths=$param_paths\n",
    "@eval @everywhere datasets=$datasets\n",
    "@eval @everywhere registration_problems=$(Dict(dataset => data_dicts[dataset][\"registration_problems\"] for dataset in datasets_freely_moving))\n",
    "@eval @everywhere params=$params\n",
    "@eval @everywhere datasets_freely_moving=$datasets_freely_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = @spawnat new_process begin\n",
    "    predict = pyimport(\"deepreg.predict\")\n",
    "    overwrite_existing = false # set this to `true` to overwrite existing registrations; otherwise the code will skip over them and focus on incomplete registrations\n",
    "    model = nothing\n",
    "    nrrd_spacing = nothing\n",
    "    for dataset in datasets_freely_moving\n",
    "        batch_size = params[dataset][\"deepreg_batch_size\"]\n",
    "        for i in 1:batch_size:length(registration_problems[dataset])\n",
    "            batch = registration_problems[dataset][i:min(i+batch_size-1, length(registration_problems[dataset]))]\n",
    "            if isfile(joinpath(param_paths[dataset][\"path_dir_reg\"], \"$(batch[end][1])to$(batch[end][2])\", \"predicted_fixed_image.nrrd\")) && !overwrite_existing\n",
    "                continue\n",
    "            end\n",
    "            fixed_images = zeros((batch_size, params[dataset][\"crop_size\"]...))\n",
    "            moving_images = zeros((batch_size, params[dataset][\"crop_size\"]...))\n",
    "            \n",
    "\n",
    "            for j in 1:length(batch)\n",
    "                moving, fixed = batch[j]\n",
    "\n",
    "                h5open(joinpath(root_path, \"euler_tfm_moving/$(moving)_$(fixed).h5\"), \"r\") do f\n",
    "                    moving_images[j,:,:,:,:] .= permutedims(read(f[\"raw\"]), (4,3,2,1)) # need to permute dims since julia and python read images in different dimensions\n",
    "                end\n",
    "\n",
    "                h5open(joinpath(root_path, \"img_fixed/$(fixed).h5\"), \"r\") do f\n",
    "                    fixed_images[j,:,:,:,:] .= permutedims(read(f[\"raw\"]), (4,3,2,1)) # need to permute dims since julia and python read images in different dimensions\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            ddf, pred_fixed_image, model = predict.unwrapped_predict(fixed_images, moving_images, \"/dev/null\", params[dataset][\"deepreg_label_size\"], params[dataset][\"deepreg_label_size\"], model, \n",
    "                    param_paths[dataset][\"path_deepreg_weights\"], joinpath(root_path, \"config_batch.yaml\"))\n",
    "            for (j, k) in enumerate(batch)\n",
    "                ddf_batch = ddf[j,:,:,:,:]\n",
    "                predicted_fixed_image_batch = pred_fixed_image[j,:,:,:,:]\n",
    "                \n",
    "                save_dir_problem = joinpath(param_paths[dataset][\"path_dir_reg\"], \"$(k[1])to$(k[2])\")\n",
    "\n",
    "                create_dir(save_dir_problem)\n",
    "            \n",
    "                h5open(joinpath(save_dir_problem, \"ddf.h5\"), \"w\") do file\n",
    "                    write(file, \"ddf\", ddf_batch)\n",
    "                end\n",
    "            \n",
    "                write_nrrd(joinpath(save_dir_problem, \"predicted_fixed_image.nrrd\"), Float32.(predicted_fixed_image_batch), (0.54, 0.54, 0.54))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(new_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform ROI images\n",
    "\n",
    "This section transforms ROI images through the DDFs generated by CellDiscoveryNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_process = addprocs(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere workers() begin\n",
    "    using ImageDataIO\n",
    "    using PyCall\n",
    "    using NRRDIO\n",
    "    using Statistics\n",
    "    using ImageRegistration\n",
    "    using FlavellBase\n",
    "    using MultivariateStats\n",
    "    using HDF5\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eval @everywhere param_paths=$param_paths\n",
    "@eval @everywhere datasets=$datasets\n",
    "@eval @everywhere registration_problems=$(Dict(dataset => data_dicts[dataset][\"registration_problems\"] for dataset in datasets_freely_moving))\n",
    "@eval @everywhere params=$params\n",
    "@eval @everywhere datasets_freely_moving=$datasets_freely_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = @spawnat new_process begin\n",
    "    tf = pyimport(\"tensorflow\")\n",
    "    layer = pyimport(\"deepreg.model.layer\")\n",
    "\n",
    "    memory_dict = Dict()\n",
    "    error_dicts = Dict()\n",
    "\n",
    "    for dataset in datasets_freely_moving\n",
    "        error_dicts[dataset] = Dict()\n",
    "        for problem in registration_problems[dataset]\n",
    "            try\n",
    "                moving, fixed = problem\n",
    "                euler_transformed_moving_roi_image = nothing\n",
    "\n",
    "                h5open(joinpath(root_path, \"euler_tfm_moving_roi\", \"$(moving)_to_$(fixed).h5\"), \"r\") do f\n",
    "                    euler_transformed_moving_roi_image = permutedims(read(f[collect(keys(f))[1]]), (3,2,1))\n",
    "                end\n",
    "\n",
    "                ddf = nothing\n",
    "        \n",
    "                h5open(joinpath(param_paths[dataset][\"path_dir_reg\"], \"$(moving)to$(fixed)\", \"ddf.h5\"), \"r\") do f\n",
    "                    ddf = read(f[\"ddf\"])\n",
    "                end\n",
    "        \n",
    "                warping = layer.Warping(fixed_image_size=params[dataset][\"crop_size\"], batch_size=1, interpolation=\"nearest\")\n",
    "                euler_transformed_moving_roi_image_tf = tf.cast(tf.expand_dims(euler_transformed_moving_roi_image, axis=0), tf.float32)\n",
    "        \n",
    "                ddf_transformed_roi_image = warping(inputs=[ddf, euler_transformed_moving_roi_image_tf]).numpy()[1,:,:,:]\n",
    "        \n",
    "                save_dir = joinpath(param_paths[dataset][\"path_dir_transformed\"], \"$(moving)to$(fixed)\")\n",
    "                create_dir(save_dir)\n",
    "        \n",
    "                write_nrrd(joinpath(save_dir, \"result.nrrd\"), floor.(UInt16, clamp.(ddf_transformed_roi_image, typemin(UInt16), typemax(UInt16))), (0.54, 0.54, 0.54))\n",
    "            catch e\n",
    "                error_dicts[dataset][problem] = e\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    error_dicts\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dict = fetch(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(new_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute centroids\n",
    "\n",
    "Compute centroids of all neuron ROIs and transform the centroids through CellDiscoveryNet's DDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    data_dicts[dataset][\"roi_centroids_recropped\"] = Dict()\n",
    "    @showprogress for t in params[dataset][\"t_range\"]\n",
    "        img_roi_watershed = nothing\n",
    "\n",
    "        h5open(joinpath(root_path, \"roi_fixed\", \"$(t).h5\"), \"r\") do f\n",
    "            img_roi_watershed = permutedims(read(f[\"roi\"]), (3,2,1)) # (x,y,z)\n",
    "        end\n",
    "\n",
    "        data_dicts[dataset][\"roi_centroids_recropped\"][t] = get_centroids_preservenum(img_roi_watershed)\n",
    "    end\n",
    "\n",
    "    data_dicts[dataset][\"roi_centroids_transformed\"] = Dict()\n",
    "    @showprogress for problem in data_dicts[dataset][\"registration_problems\"]\n",
    "        img_roi_watershed = read_img(NRRD(joinpath(param_paths[dataset][\"path_dir_transformed\"], \"$(problem[1])to$(problem[2])\", \"result.nrrd\")))\n",
    "        data_dicts[dataset][\"roi_centroids_transformed\"][problem] = get_centroids_preservenum(img_roi_watershed)\n",
    "    end\n",
    "    \n",
    "    data_dicts[dataset][\"roi_displacement\"] = Dict()\n",
    "    @showprogress for problem in data_dicts[dataset][\"registration_problems\"]\n",
    "        moving, fixed = problem\n",
    "        data_dicts[dataset][\"roi_displacement\"][problem] = Dict()\n",
    "        ddf = Dict()\n",
    "        h5open(joinpath(param_paths[dataset][\"path_dir_reg\"], \"$(moving)to$(fixed)\", \"ddf.h5\"), \"r\") do f\n",
    "            ddf[\"ddf\"] = read(f[\"ddf\"])\n",
    "        end\n",
    "        ddf = ddf[\"ddf\"]\n",
    "\n",
    "        fixed_roi = nothing\n",
    "        h5open(joinpath(root_path, \"roi_fixed\", \"$(fixed).h5\"), \"r\") do f\n",
    "            fixed_roi = permutedims(read(f[\"roi\"]), (3,2,1))\n",
    "        end\n",
    "\n",
    "        dist_dict = Dict()\n",
    "        for i in 1:size(data_dicts[dataset][\"roi_centroids_recropped\"][problem[2]],1)\n",
    "            x, y, z = Int.(round.(data_dicts[dataset][\"roi_centroids_recropped\"][problem[2]][i,:]))\n",
    "            if x > 0\n",
    "                dist_dict[i] = [norm(ddf[x,y,z,:])]\n",
    "            end\n",
    "        end\n",
    "        for roi_val in keys(dist_dict)\n",
    "            data_dicts[dataset][\"roi_displacement\"][problem][roi_val] = mean(dist_dict[roi_val])\n",
    "        end\n",
    "    end\n",
    "    data_dicts[dataset][\"centroid_dist_dict\"] = compute_centroid_dist_dict(data_dicts[dataset][\"roi_centroids_recropped\"], data_dicts[dataset][\"roi_centroids_transformed\"], max_dist=params[dataset][\"max_centroid_dist\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    data_dicts[dataset][\"roi_centroids_euler_tfm\"] = Dict()\n",
    "    @showprogress for (moving, fixed) in data_dicts[dataset][\"registration_problems\"]\n",
    "        img_roi_watershed = nothing\n",
    "\n",
    "        h5open(joinpath(root_path_data, \"euler_tfm_moving_roi\", \"$(moving)_to_$(fixed).h5\"), \"r\") do f\n",
    "            img_roi_watershed = permutedims(read(f[collect(keys(f))[1]]), (3,2,1))\n",
    "        end\n",
    "\n",
    "        data_dicts[dataset][\"roi_centroids_euler_tfm\"][(moving, fixed)] = get_centroids_preservenum(Int.(img_roi_watershed))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    data_dicts[dataset][\"euler_centroid_dist_dict\"] = compute_centroid_dist_dict(data_dicts[dataset][\"roi_centroids_recropped\"], data_dicts[dataset][\"roi_centroids_euler_tfm\"], max_dist=params[dataset][\"max_centroid_dist\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute nonrigidity of the DDF transformations\n",
    "\n",
    "This is used as a heuristic. More nonrigid DDFs are weighted less heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_process = addprocs(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere workers() begin\n",
    "    using HDF5\n",
    "    using PyCall\n",
    "    using ImageDataIO\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eval @everywhere param_paths=$param_paths\n",
    "@eval @everywhere datasets=$datasets\n",
    "@eval @everywhere registration_problems=$(Dict(dataset => data_dicts[dataset][\"registration_problems\"] for dataset in datasets_freely_moving))\n",
    "@eval @everywhere params=$params\n",
    "@eval @everywhere datasets_freely_moving=$datasets_freely_moving\n",
    "@eval @everywhere dataset_central=$dataset_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = @spawnat new_process begin\n",
    "    reg_metric_dict = Dict()\n",
    "\n",
    "    deepreg_loss = pyimport(\"deepreg.loss.deform\")\n",
    "    nonrigid_penalty = deepreg_loss.NonRigidPenalty(params[dataset_central][\"crop_size\"])\n",
    "\n",
    "    for dataset in datasets_freely_moving\n",
    "        reg_metric_dict[dataset] = Dict()\n",
    "    \n",
    "        for problem in registration_problems[dataset]\n",
    "            ddf_ = zeros(params[dataset][\"crop_size\"][1:3]..., 3)\n",
    "            file_path = joinpath(param_paths[dataset][\"path_dir_reg\"], \"$(problem[1])to$(problem[2])\", \"ddf.h5\")\n",
    "        \n",
    "            h5open(file_path, \"r\") do file\n",
    "                ddf_[:,:,:,:] .= file[\"ddf\"][:,:,:,:]\n",
    "                ddf_ = reshape(ddf_, (1, size(ddf_)...))\n",
    "            end\n",
    "        \n",
    "            if isnothing(ddf_)\n",
    "                @warn \"No DDF found for $(problem[1])to$(problem[2])\"\n",
    "                continue\n",
    "            end\n",
    "        \n",
    "            reg_metric_dict[dataset][problem] = Dict()\n",
    "            reg_metric_dict[dataset][problem][\"nonrigid_penalty\"] = nonrigid_penalty(ddf_).numpy()[1]\n",
    "        end\n",
    "    end\n",
    "    reg_metric_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    data_dicts[dataset][\"reg_metric_dict\"] = result[dataset]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(new_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset = keys(datasets)\n",
    "    data_dict = data_dicts[dataset]\n",
    "    data_dict[\"t_range\"] = params[dataset][\"t_range\"]\n",
    "    JLD2.@save(param_paths[dataset][\"path_data_dict\"], data_dict)\n",
    "end\n",
    "\n",
    "for dataset = datasets_register\n",
    "    data_dict = data_dicts[\"$(dataset)_to_central\"]\n",
    "    JLD2.@save(joinpath(param_paths[dataset_central][\"path_root_process\"], \"$(dataset)_registered_data_dict.jld2\"), data_dict)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make quality dictionary\n",
    "\n",
    "This code computes a NCC-based metric for how well each registration did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in keys(datasets)\n",
    "    evaluation_functions = Dict()\n",
    "    param = params[dataset]\n",
    "    param_path = param_paths[dataset]\n",
    "    data_dict = data_dicts[dataset]\n",
    "    error_dict = error_dicts[dataset]\n",
    "    \n",
    "    path_fixed = (dataset in datasets_freely_moving) ? param_path[\"path_dir_nrrd_filt_recropped\"] : param_path[\"path_dir_nrrd\"]\n",
    "    \n",
    "    function eval_fn(moving, fixed, resolution)\n",
    "        fixed_img = nothing\n",
    "        \n",
    "        h5open(joinpath(root_path, \"img_fixed/$(fixed).h5\"), \"r\") do f\n",
    "            fixed_img = permutedims(read(f[\"raw\"]), (4,3,2,1)) # need to permute dims since julia and python read images in different dimensions\n",
    "        end\n",
    "        pred_fixed_img = read_img(NRRD(joinpath(param_path[\"path_dir_reg\"], \"$(moving)to$(fixed)\", \"predicted_fixed_image.nrrd\")))\n",
    "        return calculate_ncc(fixed_img, pred_fixed_img)\n",
    "    end\n",
    "\n",
    "    evaluation_functions[param[\"quality_metric\"]] = eval_fn\n",
    "    data_dict[\"q_dict\"], data_dict[\"best_reg\"], error_dict[\"q_dict_errors\"] = make_quality_dict(param_path, param, data_dict[\"registration_problems\"], evaluation_functions);\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in keys(datasets)\n",
    "    for k in keys(data_dicts[dataset][\"q_dict\"])\n",
    "        for r in keys(data_dicts[dataset][\"q_dict\"][k])\n",
    "            if isnan(data_dicts[dataset][\"q_dict\"][k][r][\"NCC\"])\n",
    "                data_dicts[dataset][\"q_dict\"][k][r][\"NCC\"] = 0.0\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction of registrations above a certain NCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    dataset = \"freely_moving\"\n",
    "    length([k for k in keys(data_dicts[\"$(dataset)\"][\"q_dict\"]) if maximum([data_dicts[\"$(dataset)\"][\"q_dict\"][k][r][\"NCC\"] for r in keys(data_dicts[\"$(dataset)\"][\"q_dict\"][k])]) > 0.8]) / length(data_dicts[\"$(dataset)\"][\"registration_problems\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get activity in each channel (color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = nothing\n",
    "img_roi_watershed_ = nothing\n",
    "\n",
    "@showprogress for t in params[dataset_central][\"t_range\"]\n",
    "    img = nothing\n",
    "        \n",
    "    h5open(joinpath(root_path, \"img_fixed\", \"$(t).h5\"), \"r\") do f\n",
    "        img = permutedims(read(f[\"raw\"]), (4,3,2,1)) # need to permute dims since julia and python read images in different dimensions\n",
    "    end\n",
    "\n",
    "    img_roi_watershed = nothing\n",
    "\n",
    "    h5open(joinpath(root_path, \"roi_fixed\", \"$(t).h5\"), \"r\") do f\n",
    "        img_roi_watershed = permutedims(read(f[\"roi\"]), (3,2,1))\n",
    "    end\n",
    "\n",
    "    for ch in 1:4\n",
    "        activity = Float64.(get_activity(img_roi_watershed, img[:,:,:,ch] .* 4095))\n",
    "        create_dir(joinpath(param_paths[dataset_central][\"path_root_process\"], \"ch$(ch)_signal\"))\n",
    "        write_activity(activity, joinpath(param_paths[dataset_central][\"path_root_process\"], \"ch$(ch)_signal\", \"$(t).txt\"))\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROI match matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    @time data_dicts[dataset][\"roi_overlaps\"], data_dicts[dataset][\"roi_activity_diff\"], error_dicts[dataset][\"overlap_errors\"] = extract_roi_overlap_deepreg_multicolor(\n",
    "        data_dicts[dataset][\"registration_problems\"], param_paths[dataset], params[dataset], joinpath(root_path, \"roi_fixed\")\n",
    "    );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_freely_moving\n",
    "    @time data_dicts[dataset][\"regmap_matrix\"], data_dicts[dataset][\"label_map\"] = make_regmap_matrix_multicolor(\n",
    "        data_dicts[dataset][\"centroid_dist_dict\"], data_dicts[dataset][\"roi_overlaps\"], \n",
    "        data_dicts[dataset][\"q_dict\"], data_dicts[dataset][\"best_reg\"], data_dicts[dataset][\"reg_metric_dict\"], \n",
    "        data_dicts[dataset][\"roi_displacement\"], param_paths[dataset], param_paths[dataset], activity_diff_weight=0.0, color_diff_weight=7.0\n",
    "    );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset = keys(datasets)\n",
    "    data_dict = data_dicts[dataset]\n",
    "    data_dict[\"t_range\"] = params[dataset][\"t_range\"]\n",
    "    JLD2.@save(param_paths[dataset][\"path_data_dict\"], data_dict)\n",
    "end\n",
    "\n",
    "for dataset = datasets_register\n",
    "    data_dict = data_dicts[\"$(dataset)_to_central\"]\n",
    "    JLD2.@save(joinpath(param_paths[dataset_central][\"path_root_process\"], \"$(dataset)_registered_data_dict.jld2\"), data_dict)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load human and AutoCellLabeler labels\n",
    "\n",
    "So far, ANTSUN 2U and CellDiscoveryNet have never used any human labels. The labels are being loaded here to check accuracy of computed unsupervised labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autolabel = pyimport(\"autolabel\")\n",
    "\n",
    "data_dicts[dataset_central][\"labels\"] = []\n",
    "@showprogress for (t, dataset) in enumerate(datasets_)\n",
    "    push!(data_dicts[dataset_central][\"labels\"], autolabel.map_roi_to_neuron(joinpath(\"/data3/adam/new_unet_train/csv_paper_2\", dataset * \" Neuron ID.csv\"), confidence_threshold=4))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"autolabels\"] = []\n",
    "@showprogress for (t, dataset) in enumerate(datasets_)\n",
    "    push!(data_dicts[dataset_central][\"autolabels\"], autolabel.map_roi_to_neuron(joinpath(\"/data3/adam/new_unet_train/csv_extracted_paper_all\", dataset * \".csv\"), confidence_threshold=3))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_ids_nolr = [\"I3\", \"MI\", \"M4\", \"RMED\", \"RMEV\", \"ALA\", \"RID\", \"M1\", \"I6\", \"RIS\", \"RIH\", \"M5\", \"I4\", \"AQR\", \"RIR\", \"VB02\", \"VB01\", \"I5\", \"AVL\", \"VA01\", \"VD01\", \"AVG\", \"DD01\", \"DB02\", \"UNKNOWN\", \"glia\", \"granule\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform clustering with different values of $w_7$\n",
    "\n",
    "The following code block clusters the registration heuristic matrix with different $w_7$ values, and computes accuracy (against humans and against autolabel) on each clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vals = Dict()\n",
    "accuracy_vals_autolabel = Dict()\n",
    "accuracy_vals_cumulative = Dict()\n",
    "accuracy_vals_cumulative_autolabel = Dict()\n",
    "cutoff_vals = [0.0] # this is a list of negative w_7 values\n",
    "for i in 1:36\n",
    "    if i != 12 # skip -1e-9, save it to the end\n",
    "        push!(cutoff_vals, -1e-12 * 10^(i/4))\n",
    "    end\n",
    "end\n",
    "\n",
    "push!(cutoff_vals, -1e-9) # add back -1e-9\n",
    "exclude = false\n",
    "@showprogress for cutoff = cutoff_vals\n",
    "    if exclude\n",
    "        data_dicts[dataset_central][\"new_label_map\"], data_dicts[dataset_central][\"inv_map\"] = find_neurons(data_dicts[dataset_central][\"regmap_matrix_exclude\"], data_dicts[dataset_central][\"label_map_exclude\"], overlap_threshold=0.00, height_threshold=cutoff);\n",
    "    else\n",
    "        data_dicts[dataset_central][\"new_label_map\"], data_dicts[dataset_central][\"inv_map\"] = find_neurons(data_dicts[dataset_central][\"regmap_matrix\"], data_dicts[dataset_central][\"label_map\"], overlap_threshold=0.00, height_threshold=cutoff);\n",
    "    end\n",
    "\n",
    "    data_dicts[dataset_central][\"inv_map_labels\"] = Dict()\n",
    "    data_dicts[dataset_central][\"inv_map_classes\"] = Dict()\n",
    "    data_dicts[dataset_central][\"inv_map_all_labels\"] = Dict()\n",
    "    data_dicts[dataset_central][\"inv_map_all_classes\"] = Dict()\n",
    "\n",
    "    data_dicts[dataset_central][\"autolabel_inv_map_labels\"] = Dict()\n",
    "    data_dicts[dataset_central][\"autolabel_inv_map_classes\"] = Dict()\n",
    "    data_dicts[dataset_central][\"autolabel_inv_map_all_labels\"] = Dict()\n",
    "    data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"] = Dict()\n",
    "\n",
    "    for n in keys(data_dicts[dataset_central][\"inv_map\"])\n",
    "        threshold = (length(datasets_) - 1) / 2 + 1\n",
    "        if exclude\n",
    "            threshold = (length(datasets_) - length(timepoints_exclude)) / 2 + 1\n",
    "        end\n",
    "        if length(data_dicts[dataset_central][\"inv_map\"][n]) < threshold\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        data_dicts[dataset_central][\"inv_map_all_classes\"][n] = []\n",
    "        data_dicts[dataset_central][\"inv_map_labels\"][n] = Dict()\n",
    "        data_dicts[dataset_central][\"inv_map_classes\"][n] = Dict()\n",
    "        data_dicts[dataset_central][\"inv_map_all_labels\"][n] = []\n",
    "\n",
    "        data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n] = []\n",
    "        data_dicts[dataset_central][\"autolabel_inv_map_labels\"][n] = Dict()\n",
    "        data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n] = Dict()\n",
    "        data_dicts[dataset_central][\"autolabel_inv_map_all_labels\"][n] = []\n",
    "\n",
    "        for t in keys(data_dicts[dataset_central][\"inv_map\"][n])\n",
    "            data_dicts[dataset_central][\"inv_map_labels\"][n][t] = []\n",
    "            data_dicts[dataset_central][\"inv_map_classes\"][n][t] = []\n",
    "\n",
    "            data_dicts[dataset_central][\"autolabel_inv_map_labels\"][n][t] = []\n",
    "            data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t] = []\n",
    "            if t == 63 # incorrectly labeled dataset (labels are mismatched with ROIs)\n",
    "                continue\n",
    "            end\n",
    "            for roi in data_dicts[dataset_central][\"inv_map\"][n][t]\n",
    "                found_label = false\n",
    "                found_autolabel = false\n",
    "                if roi in keys(data_dicts[dataset_central][\"labels\"][t][1])\n",
    "                    append!(data_dicts[dataset_central][\"inv_map_all_labels\"][n], data_dicts[dataset_central][\"labels\"][t][1][roi])\n",
    "                    for label in data_dicts[dataset_central][\"labels\"][t][1][roi]\n",
    "                        push!(data_dicts[dataset_central][\"inv_map_labels\"][n][t], label)\n",
    "                        if occursin(\"-alt\", label)\n",
    "                            label = label[1:end-4]\n",
    "                        end\n",
    "                        if !(label in neuron_ids_nolr)\n",
    "                            label = label[1:end-1]\n",
    "                        end\n",
    "                        if occursin(\"?\", label)\n",
    "                            continue\n",
    "                        end\n",
    "                        push!(data_dicts[dataset_central][\"inv_map_all_classes\"][n], label)\n",
    "                        push!(data_dicts[dataset_central][\"inv_map_classes\"][n][t], label)\n",
    "                        found_label = true\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                if !found_label\n",
    "                    push!(data_dicts[dataset_central][\"inv_map_labels\"][n][t], \"UNKNOWN\")\n",
    "                    push!(data_dicts[dataset_central][\"inv_map_classes\"][n][t], \"UNKNOWN\")\n",
    "                end\n",
    "\n",
    "                if t == 61\n",
    "                    continue\n",
    "                end\n",
    "                if roi in keys(data_dicts[dataset_central][\"autolabels\"][t][1])\n",
    "                    append!(data_dicts[dataset_central][\"autolabel_inv_map_all_labels\"][n], data_dicts[dataset_central][\"autolabels\"][t][1][roi])\n",
    "                    for label in data_dicts[dataset_central][\"autolabels\"][t][1][roi]\n",
    "                        push!(data_dicts[dataset_central][\"autolabel_inv_map_labels\"][n][t], label)\n",
    "                        if occursin(\"-alt\", label)\n",
    "                            label = label[1:end-4]\n",
    "                        end\n",
    "                        if !(label in neuron_ids_nolr)\n",
    "                            label = label[1:end-1]\n",
    "                        end\n",
    "                        if occursin(\"?\", label)\n",
    "                            continue\n",
    "                        end\n",
    "                        push!(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n], label)\n",
    "                        push!(data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t], label)\n",
    "                        found_autolabel = true\n",
    "                    end\n",
    "                end\n",
    "\n",
    "\n",
    "                if !found_autolabel\n",
    "                    push!(data_dicts[dataset_central][\"autolabel_inv_map_labels\"][n][t], \"UNKNOWN\")\n",
    "                    push!(data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t], \"UNKNOWN\")\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    accuracy_vals[cutoff] = Dict()\n",
    "    n_correct = 0\n",
    "    n_incorrect = 0\n",
    "    for n in keys(data_dicts[dataset_central][\"inv_map_all_classes\"])\n",
    "        accuracy_vals[cutoff][n] = Dict()\n",
    "        most_common = countmap(data_dicts[dataset_central][\"inv_map_all_classes\"][n])\n",
    "        if length(most_common) == 0\n",
    "            accuracy_vals[cutoff][n] = 0\n",
    "            continue\n",
    "        end\n",
    "        if length(data_dicts[dataset_central][\"inv_map_all_classes\"][n]) > 2\n",
    "            n_correct += maximum(values(most_common))\n",
    "            n_incorrect += length(data_dicts[dataset_central][\"inv_map_all_classes\"][n]) - maximum(values(most_common))\n",
    "        elseif cutoff == -1e-9\n",
    "            println(n)\n",
    "        end\n",
    "        accuracy_vals[cutoff][n] = maximum(values(most_common)) / length(data_dicts[dataset_central][\"inv_map_all_classes\"][n])\n",
    "    end\n",
    "\n",
    "    accuracy_vals_cumulative[cutoff] = n_correct / (n_correct + n_incorrect)\n",
    "\n",
    "    n_correct_autolabel = 0\n",
    "    n_incorrect_autolabel = 0\n",
    "    accuracy_vals_autolabel[cutoff] = Dict()\n",
    "    for n in keys(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"])\n",
    "        accuracy_vals_autolabel[cutoff][n] = Dict()\n",
    "        most_common = countmap(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n])\n",
    "        if length(most_common) == 0\n",
    "            accuracy_vals_autolabel[cutoff][n] = 0\n",
    "            continue\n",
    "        end\n",
    "        if length(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n]) > 2\n",
    "            n_correct_autolabel += maximum(values(most_common))\n",
    "            n_incorrect_autolabel += length(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n]) - maximum(values(most_common))\n",
    "        end\n",
    "        accuracy_vals_autolabel[cutoff][n] = maximum(values(most_common)) / length(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n])\n",
    "    end\n",
    "\n",
    "    accuracy_vals_cumulative_autolabel[cutoff] = n_correct_autolabel / (n_correct_autolabel + n_incorrect_autolabel)\n",
    "end\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy value at $w_7 = 10^{-9}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vals_cumulative[-1e-9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy vs number of neurons tradeoff curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_accuracy = []\n",
    "mean_accuracy = []\n",
    "cum_accuracy = []\n",
    "n_detection = []\n",
    "\n",
    "selected_point = -1e-9\n",
    "\n",
    "for cutoff in reverse(sort(collect(keys(accuracy_vals))))\n",
    "    if length(accuracy_vals[cutoff]) > 5\n",
    "        push!(med_accuracy, median(values(accuracy_vals[cutoff])))\n",
    "        push!(mean_accuracy, mean(values(accuracy_vals[cutoff])))\n",
    "        push!(n_detection, length(values(accuracy_vals[cutoff])))\n",
    "        push!(cum_accuracy, accuracy_vals_cumulative[cutoff])\n",
    "    end\n",
    "    # uncomment the following line of code to print out accuracy values\n",
    "    # println(cutoff, \" \", accuracy_vals_cumulative[cutoff], \" \", length(values(accuracy_vals[cutoff])))\n",
    "end\n",
    "\n",
    "gr()\n",
    "Plots.scatter(cum_accuracy, n_detection, label=nothing, size=(210,130), color=\"#1f77b4\")\n",
    "Plots.scatter!([accuracy_vals_cumulative[selected_point]], [length(values(accuracy_vals[selected_point]))], label=L\"w_7=10^{-9}\", color=\"red\", legend=:bottomleft)\n",
    "# Plots.xlabel!(\"ANTSUN-Unsupervised accuracy\")\n",
    "# Plots.ylabel!(\"Number of linked neuron IDs\")\n",
    "Plots.ylims!(0,150)\n",
    "Plots.xlims!(0.9, 1.0001)\n",
    "Plots.xticks!(0.9:0.02:1.0)\n",
    "plot!(\n",
    "    xguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    yguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    xtickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    ytickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    grid = false,\n",
    "    tickdir=:out\n",
    ")\n",
    "\n",
    "Plots.savefig(\"/data3/prj_register/figures/figure_6/accuracy_vs_detection.pdf\")\n",
    "Plots.plot!()\n",
    "# Plots.ylims!(0,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute centroid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"inv_labels\"] = []\n",
    "\n",
    "for (t, dataset) in enumerate(datasets_)\n",
    "    push!(data_dicts[dataset_central][\"inv_labels\"], Dict())\n",
    "    for roi in keys(data_dicts[dataset_central][\"labels\"][t][1])\n",
    "        for i in 1:length(data_dicts[dataset_central][\"labels\"][t][1][roi])\n",
    "            neuron = data_dicts[dataset_central][\"labels\"][t][1][roi][i]\n",
    "            if !(neuron in keys(data_dicts[dataset_central][\"inv_labels\"][t]))\n",
    "                data_dicts[dataset_central][\"inv_labels\"][t][neuron] = []\n",
    "            end\n",
    "            push!(data_dicts[dataset_central][\"inv_labels\"][t][neuron], roi)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"label_centroid_distance\"] = []\n",
    "data_dicts[dataset_central][\"label_centroid_distance_highncc\"] = []\n",
    "data_dicts[dataset_central][\"euler_label_centroid_distance\"] = []\n",
    "data_dicts[dataset_central][\"label_centroid_distance_train\"] = []\n",
    "data_dicts[dataset_central][\"label_centroid_distance_valtest\"] = []\n",
    "ncc_dist = Float64[]\n",
    "\n",
    "for problem in data_dicts[dataset_central][\"registration_problems\"]\n",
    "    push!(ncc_dist, data_dicts[dataset_central][\"q_dict\"][problem][(0,0)][\"NCC\"])\n",
    "end\n",
    "\n",
    "perc_90_ncc = quantile(ncc_dist, 0.9)\n",
    "@showprogress for problem in data_dicts[dataset_central][\"registration_problems\"]\n",
    "    dist_problem = []\n",
    "    moving, fixed = problem\n",
    "    if moving == 63 || fixed == 63 # corrupted labels\n",
    "        continue\n",
    "    end\n",
    "    for (label_moving, rois_moving) in data_dicts[dataset_central][\"inv_labels\"][moving]\n",
    "        for (label_fixed, rois_fixed) in data_dicts[dataset_central][\"inv_labels\"][fixed]\n",
    "            # compute centroid distance only over matching labels\n",
    "            if label_moving != label_fixed\n",
    "                continue\n",
    "            end\n",
    "            # ignore labels contianing '?' character\n",
    "            if occursin(\"?\", label_moving) || occursin(\"?\", label_fixed)\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            rois_moving = [r for r in rois_moving if r <= size(data_dicts[dataset_central][\"roi_centroids_transformed\"][(moving, fixed)],1)]\n",
    "            rois_fixed = [r for r in rois_fixed if r <= size(data_dicts[dataset_central][\"roi_centroids_recropped\"][fixed],1)]\n",
    "\n",
    "            centroid_moving = mean(data_dicts[dataset_central][\"roi_centroids_transformed\"][(moving, fixed)][rois_moving,:], dims=1)\n",
    "            centroid_euler_moving = mean(data_dicts[dataset_central][\"roi_centroids_euler_tfm\"][(moving, fixed)][rois_moving,:], dims=1)\n",
    "            centroid_fixed = mean(data_dicts[dataset_central][\"roi_centroids_recropped\"][fixed][rois_fixed,:], dims=1)\n",
    "\n",
    "            if centroid_moving[1] < 0 || centroid_fixed[1] < 0\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            dist = norm(centroid_moving .- centroid_fixed)\n",
    "            if isnan(dist)\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            push!(data_dicts[dataset_central][\"label_centroid_distance\"], dist)\n",
    "            if problem[1] <= length(datasets_train) && problem[2] <= length(datasets_train)\n",
    "                push!(data_dicts[dataset_central][\"label_centroid_distance_train\"], dist)\n",
    "            else\n",
    "                push!(data_dicts[dataset_central][\"label_centroid_distance_valtest\"], dist)\n",
    "            end\n",
    "            push!(data_dicts[dataset_central][\"euler_label_centroid_distance\"], norm(centroid_euler_moving .- centroid_fixed))\n",
    "            if data_dicts[dataset_central][\"q_dict\"][problem][(0,0)][\"NCC\"] > perc_90_ncc\n",
    "                push!(data_dicts[dataset_central][\"label_centroid_distance_highncc\"], dist)\n",
    "            end\n",
    "            # if norm(centroid_euler_moving .- centroid_fixed) > 200\n",
    "            #     println(moving, \" \", fixed, \" \", label_moving, \" \", label_fixed, \" \", rois_moving, \" \", rois_fixed, \" \", dist, \" \", norm(centroid_euler_moving .- centroid_fixed))\n",
    "            # end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average number of labels per animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_include = length(datasets_) - 1 # subtract 1 for dataset 63 which has incorrect labels and is excluded\n",
    "\n",
    "sum([length(data_dicts[dataset_central][\"inv_map\"][x]) for x in keys(data_dicts[dataset_central][\"inv_map\"]) if length(data_dicts[dataset_central][\"inv_map\"][x]) > len_include / 2]) / len_include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NCC distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    ncc_dist = Float64[]\n",
    "    train_ncc_dist = Float64[]\n",
    "    val_test_ncc_dist = Float64[]\n",
    "    for problem in data_dicts[dataset_central][\"registration_problems\"]\n",
    "        push!(ncc_dist, data_dicts[dataset_central][\"q_dict\"][problem][(0,0)][\"NCC\"])\n",
    "        if problem[1] <= length(datasets_train) && problem[2] <= length(datasets_train)\n",
    "            push!(train_ncc_dist, data_dicts[dataset_central][\"q_dict\"][problem][(0,0)][\"NCC\"])\n",
    "        else\n",
    "            push!(val_test_ncc_dist, data_dicts[dataset_central][\"q_dict\"][problem][(0,0)][\"NCC\"])\n",
    "        end\n",
    "    end\n",
    "    println(length(train_ncc_dist))\n",
    "    println(mean(ncc_dist))\n",
    "    println(median(ncc_dist))\n",
    "    println(percentile(ncc_dist, 90))\n",
    "    println(mean(train_ncc_dist))\n",
    "    println(mean(val_test_ncc_dist))\n",
    "\n",
    "    println(median(ncc_dist))\n",
    "\n",
    "    gr()\n",
    "    StatsPlots.violin([ncc_dist, train_ncc_dist, val_test_ncc_dist], label=nothing, size=(210,130),  color=\"#1f77b4\")\n",
    "\n",
    "    plot!(\n",
    "        xguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "        yguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "        xtickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "        ytickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "        grid = false,\n",
    "        tickdir=:out\n",
    "    )\n",
    "    ylims!(0,1)\n",
    "    # ylabel!(\"NCC\")\n",
    "    xticks!(1:3, [\"All\", \"Train\", \"Val+\\nTest\"])\n",
    "\n",
    "end\n",
    "\n",
    "Plots.savefig(\"/data3/prj_register/figures/figure_6/NCC_violin.pdf\")\n",
    "plot!()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot centroid distance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr()\n",
    "StatsPlots.violin([log.(2, x) for x in [#data_dicts[dataset_central][\"euler_label_centroid_distance\"],\n",
    "        data_dicts[dataset_central][\"label_centroid_distance\"], \n",
    "        data_dicts[dataset_central][\"label_centroid_distance_train\"], \n",
    "        data_dicts[dataset_central][\"label_centroid_distance_valtest\"], \n",
    "        data_dicts[dataset_central][\"label_centroid_distance_highncc\"]]],\n",
    "    label=nothing, size=(210,130), color=\"#1f77b4\", scale=:area)\n",
    "\n",
    "\n",
    "println(median(data_dicts[dataset_central][\"euler_label_centroid_distance\"]))\n",
    "println(median(data_dicts[dataset_central][\"label_centroid_distance\"]))\n",
    "println(percentile(data_dicts[dataset_central][\"label_centroid_distance\"], 20))\n",
    "println(mean(data_dicts[dataset_central][\"label_centroid_distance\"]))\n",
    "println(median(data_dicts[dataset_central][\"label_centroid_distance_train\"]))\n",
    "println(median(data_dicts[dataset_central][\"label_centroid_distance_valtest\"]))\n",
    "println(median(data_dicts[dataset_central][\"label_centroid_distance_highncc\"]))\n",
    "println(percentile(data_dicts[dataset_central][\"label_centroid_distance_highncc\"], 20))\n",
    "ylims!(-4,8)\n",
    "yticks!(-4:2:8, [\"1/16\", \"1/4\", \"1\", \"4\", \"16\", \"64\", \"256\"])\n",
    "xticks!(1:4, [\"All\", \"Train\", \"Val+\\nTest\", \"High\\nNCC\"])\n",
    "# ylabel!(\"Centroid distance\")\n",
    "plot!(\n",
    "    xguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    yguidefont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    xtickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    ytickfont = font(\"DejaVu Sans\", pointsize=7),\n",
    "    grid = false,\n",
    "    tickdir=:out\n",
    ")\n",
    "Plots.savefig(\"/data3/prj_register/figures/figure_6/centroid_distance_violin.pdf\")\n",
    "Plots.plot!()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot matrix of labels per animal\n",
    "\n",
    "Each entry in the matrix is one label detected in one animal. Its color indicates accuracy - green means accurate (matching plurality label), orange means inaccurate, blue means not labeled by the ground truth human labeler, and black means not labeled by ANTSUN 2U."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this analysis is based on human labels, we have to exclude dataset 63 which has incorrect labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[dataset_central][\"t_range\"] = [t for t in 1:102 if t != 63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"labels_deepreg\"] = Dict()\n",
    "thresh = 3 # number of matching labels needed to give a row label\n",
    "\n",
    "let\n",
    "    unknown_new = []\n",
    "    u_count = 0\n",
    "    mtx = zeros(length(keys(data_dicts[dataset_central][\"inv_map_classes\"])), length(params[dataset_central][\"t_range\"]))\n",
    "    labels = []\n",
    "    for (i, n) in enumerate(collect(keys(data_dicts[dataset_central][\"inv_map_classes\"])))\n",
    "        most_common = countmap(data_dicts[dataset_central][\"inv_map_all_classes\"][n])\n",
    "        if length(most_common) == 0 || maximum(values(most_common)) < thresh\n",
    "            most_common_label = \"UNKNOWN\"\n",
    "        else\n",
    "            most_common_label = first(sort(collect(most_common), by=x->x[2], rev=true))[1]\n",
    "        end\n",
    "\n",
    "        # now disambiguate L/R (mostly for CSV output file purposes, as L/R is not currently used in analysis)\n",
    "        valid_labels = [most_common_label]\n",
    "        if !(most_common_label in neuron_ids_nolr)\n",
    "            valid_labels = [most_common_label * \"L\", most_common_label * \"R\"]\n",
    "        end\n",
    "        most_common_full = countmap([label for label in data_dicts[dataset_central][\"inv_map_all_labels\"][n] if label in valid_labels])\n",
    "        if (length(most_common_full) == 0) || (maximum(values(most_common)) < thresh)\n",
    "            @assert(most_common_label == \"UNKNOWN\")\n",
    "            most_common_full_label = \"NEW \" * string(u_count + 1)\n",
    "            u_count += 1\n",
    "            push!(unknown_new, length([k for k in keys(data_dicts[dataset_central][\"inv_map\"][n]) if k != 63]))\n",
    "        else\n",
    "            most_common_full_label = first(sort(collect(most_common_full), by=x->x[2], rev=true))[1]\n",
    "        end\n",
    "\n",
    "        push!(labels, most_common_full_label)\n",
    "\n",
    "\n",
    "        most_common_class = most_common_full_label\n",
    "        if !(most_common_full_label in neuron_ids_nolr)\n",
    "            most_common_class = most_common_full_label[1:end-1]\n",
    "        end\n",
    "\n",
    "        if most_common_class != most_common_label\n",
    "            @warn((n, \" \", most_common_label, \" \", most_common_full_label))\n",
    "        end\n",
    "\n",
    "        for (j, t) in enumerate(params[dataset_central][\"t_range\"])\n",
    "            if !(t in keys(data_dicts[dataset_central][\"inv_map_classes\"][n]))\n",
    "                mtx[i,j] = 0\n",
    "            elseif length(data_dicts[dataset_central][\"inv_map_classes\"][n][t]) == 0\n",
    "                mtx[i,j] = 1\n",
    "            elseif length(data_dicts[dataset_central][\"inv_map_classes\"][n][t]) > 1\n",
    "                mtx[i,j] = 2\n",
    "            else\n",
    "                label = data_dicts[dataset_central][\"inv_map_classes\"][n][t][1]\n",
    "                if label == \"UNKNOWN\" || most_common_label == \"UNKNOWN\"\n",
    "                    mtx[i,j] = 3\n",
    "                elseif label != most_common_label\n",
    "                    mtx[i,j] = 4\n",
    "                else\n",
    "                    mtx[i,j] = 5\n",
    "                end\n",
    "            end\n",
    "            if !(t in keys(data_dicts[dataset_central][\"inv_map\"][n]))\n",
    "                continue\n",
    "            end\n",
    "            if !(t in keys(data_dicts[dataset_central][\"labels_deepreg\"]))\n",
    "                data_dicts[dataset_central][\"labels_deepreg\"][t] = Dict()\n",
    "            end\n",
    "            for roi in data_dicts[dataset_central][\"inv_map\"][n][t]\n",
    "                @assert !(roi in keys(data_dicts[dataset_central][\"labels_deepreg\"][t]))\n",
    "                data_dicts[dataset_central][\"labels_deepreg\"][t][roi] = most_common_full_label\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    mtx_autolabel = zeros(length(keys(data_dicts[dataset_central][\"autolabel_inv_map_classes\"])), length(params[dataset_central][\"t_range\"]))\n",
    "    labels_autolabel = []\n",
    "    for (i, n) in enumerate(collect(keys(data_dicts[dataset_central][\"autolabel_inv_map_classes\"])))\n",
    "        most_common = countmap(data_dicts[dataset_central][\"autolabel_inv_map_all_classes\"][n])\n",
    "        if length(most_common) == 0\n",
    "            most_common_label = \"UNKNOWN\"\n",
    "        else\n",
    "            most_common_label = first(sort(collect(most_common), by=x->x[2], rev=true))[1]\n",
    "        end\n",
    "        push!(labels_autolabel, most_common_label)\n",
    "        for (j, t) in enumerate(params[dataset_central][\"t_range\"])\n",
    "            if !(t in keys(data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n]))\n",
    "                mtx_autolabel[i,j] = 0\n",
    "            elseif length(data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t]) == 0\n",
    "                mtx_autolabel[i,j] = 1\n",
    "            elseif length(data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t]) > 1\n",
    "                mtx_autolabel[i,j] = 2\n",
    "                println(n, \" \", t)\n",
    "            else\n",
    "                label = data_dicts[dataset_central][\"autolabel_inv_map_classes\"][n][t][1]\n",
    "                if label == \"UNKNOWN\" || most_common_label == \"UNKNOWN\"\n",
    "                    mtx_autolabel[i,j] = 3\n",
    "                elseif label != most_common_label\n",
    "                    mtx_autolabel[i,j] = 4\n",
    "                else\n",
    "                    mtx_autolabel[i,j] = 5\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Sort columns of matrix by number of incorrect (4) labels\n",
    "    incorrect_labels = sum(mtx .== 4, dims=1)[1,:] ./ (sum(mtx .== 4, dims=1)[1,:] .+ sum(mtx .== 5, dims=1)[1,:])\n",
    "\n",
    "    # Function to compute categorical distance between two vectors\n",
    "    function categorical_dist(a, b)\n",
    "        sum(a .!= b)\n",
    "    end\n",
    "\n",
    "    # Compute the row distance matrix\n",
    "    num_rows = size(mtx, 1)\n",
    "    row_dist = zeros(num_rows, num_rows)\n",
    "    for i in 1:num_rows\n",
    "        for j in 1:num_rows\n",
    "            row_dist[i, j] = categorical_dist(mtx[i, :], mtx[j, :])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Compute the column distance matrix\n",
    "    num_cols = size(mtx, 2)\n",
    "    col_dist = zeros(num_cols, num_cols)\n",
    "    for i in 1:num_cols\n",
    "        for j in 1:num_cols\n",
    "            col_dist[i, j] = categorical_dist(mtx[:, i], mtx[:, j])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    row_clustering = hclust(row_dist, linkage=:average)\n",
    "    col_clustering = hclust(col_dist, linkage=:average)\n",
    "\n",
    "    # Get the order of rows and columns\n",
    "    row_order = row_clustering.order\n",
    "    col_order = col_clustering.order\n",
    "\n",
    "    # Reorder the matrix\n",
    "    reordered_mtx = mtx[row_order, col_order]\n",
    "    reordered_mtx_autolabel = mtx_autolabel[row_order, col_order]\n",
    "    reordered_labels = labels[row_order]\n",
    "    reordered_labels_autolabel = labels_autolabel[row_order]\n",
    "\n",
    "    cmap = PyPlot.matplotlib.colors.ListedColormap([\"black\", \"red\", \"C0\", \"C0\", \"C1\", \"C2\"])\n",
    "    figure(figsize=(10,10))\n",
    "    imshow(reordered_mtx, cmap=cmap)\n",
    "    font = Dict(\"family\" => \"DejaVu Sans\", \"size\" => 7)\n",
    "\n",
    "    PyPlot.xlabel(\"dataset\", fontdict=font)\n",
    "\n",
    "    PyPlot.yticks(0:length(reordered_labels)-1, reordered_labels, fontsize=5, fontname=\"DejaVu Sans\")\n",
    "    PyPlot.xticks([], [], fontsize=7, fontname=\"DejaVu Sans\")\n",
    "\n",
    "    PyPlot.ylabel(\"neuron\", fontdict=font)\n",
    "\n",
    "    create_dir(\"/data3/prj_register/figures/figure_S6\")\n",
    "    PyPlot.savefig(\"/data3/prj_register/figures/figure_S6/full_label_mtx.pdf\")\n",
    "\n",
    "    figure(figsize=(10,10))\n",
    "    imshow(reordered_mtx_autolabel, cmap=cmap)\n",
    "    font = Dict(\"family\" => \"DejaVu Sans\", \"size\" => 7)\n",
    "\n",
    "    PyPlot.xlabel(\"animal\", fontdict=font)\n",
    "\n",
    "    PyPlot.yticks(0:length(reordered_labels_autolabel)-1, reordered_labels_autolabel, fontsize=5, fontname=\"DejaVu Sans\")\n",
    "    PyPlot.xticks([], [], fontsize=7, fontname=\"DejaVu Sans\")\n",
    "\n",
    "    PyPlot.ylabel(\"neuron\", fontdict=font)\n",
    "\n",
    "    labels_sorted = sort(collect(labels))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute number of labeled neurons per animal in each of the testing datasets, for comparison with AutoCellLabeler and human relabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = []\n",
    "\n",
    "for idx=92:102\n",
    "    push!(n_labels, length(data_dicts[dataset_central][\"labels_deepreg\"][idx]))\n",
    "end\n",
    "\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to output ANTSUN 2U labels in the same format as AutoCellLabeler outputs, compatible with any post-processing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_csv_files(output_dir::String, labels::Dict, roi_coords::Dict, datasets::Vector{String}, add_qm::Bool=true, neuron_ids_nolr::Vector{String}=neuron_ids_nolr)\n",
    "    create_dir(output_dir)\n",
    "    for (dataset_idx, label_dict) in labels\n",
    "        dataset_name = datasets[dataset_idx]\n",
    "        csv_filename = joinpath(output_dir, \"$dataset_name Neuron ID.csv\")\n",
    "        \n",
    "        # Prepare the data\n",
    "        neuron_class = String[]\n",
    "        coordinates = String[]\n",
    "        roi_id = Int[]\n",
    "        confidence = Int[]\n",
    "        notes = String[]\n",
    "        \n",
    "        for (roi_idx, label) in label_dict\n",
    "            if add_qm && !(label in neuron_ids_nolr)\n",
    "                label = label * \"?\"\n",
    "            end\n",
    "            push!(neuron_class, label)\n",
    "            coord = roi_coords[dataset_idx][roi_idx, :]\n",
    "            push!(coordinates, \"$(coord[1]),$(coord[2]),$(coord[3])\")\n",
    "            push!(roi_id, roi_idx)\n",
    "            push!(confidence, 5)\n",
    "            push!(notes, \"\")\n",
    "        end\n",
    "        \n",
    "        # Create DataFrame with spaces in column names\n",
    "        df = DataFrame(\n",
    "            Symbol(\"Neuron Class\") => neuron_class, \n",
    "            Symbol(\"Coordinates\") => coordinates, \n",
    "            Symbol(\"ROI ID\") => roi_id, \n",
    "            Symbol(\"Confidence\") => confidence, \n",
    "            Symbol(\"Notes\") => notes\n",
    "        )\n",
    "        \n",
    "        # Write DataFrame to CSV\n",
    "        CSV.write(csv_filename, df)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign \"UNKNOWN\" label to all unlabeled ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts[dataset_central][\"padded_labels_deepreg\"] = Dict()\n",
    "\n",
    "for dataset_idx in keys(data_dicts[dataset_central][\"labels_deepreg\"])\n",
    "    data_dicts[dataset_central][\"padded_labels_deepreg\"][dataset_idx] = Dict()\n",
    "    for roi in keys(data_dicts[dataset_central][\"labels_deepreg\"][dataset_idx])\n",
    "        data_dicts[dataset_central][\"padded_labels_deepreg\"][dataset_idx][roi] = data_dicts[dataset_central][\"labels_deepreg\"][dataset_idx][roi]\n",
    "        if occursin(\"UNKNOWN\", data_dicts[dataset_central][\"labels_deepreg\"][dataset_idx][roi])\n",
    "            data_dicts[dataset_central][\"padded_labels_deepreg\"][dataset_idx][roi] = \"UNKNOWN\"\n",
    "        end\n",
    "    end\n",
    "    for roi in 1:size(data_dicts[dataset_central][\"roi_centroids_recropped\"][dataset_idx], 1)\n",
    "        if !(roi in keys(data_dicts[dataset_central][\"padded_labels_deepreg\"][dataset_idx]))\n",
    "            data_dicts[dataset_central][\"padded_labels_deepreg\"][dataset_idx][roi] = \"UNKNOWN\"\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_files(joinpath(param_paths[dataset_central][\"path_root_process\"], \"csv_deepreg\"), data_dicts[dataset_central][\"padded_labels_deepreg\"], data_dicts[dataset_central][\"roi_centroids_recropped\"], datasets_, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset = keys(datasets)\n",
    "    data_dict = data_dicts[dataset]\n",
    "    data_dict[\"t_range\"] = params[dataset][\"t_range\"]\n",
    "    JLD2.@save(param_paths[dataset][\"path_data_dict\"], data_dict)\n",
    "end\n",
    "\n",
    "for dataset = datasets_register\n",
    "    data_dict = data_dicts[\"$(dataset)_to_central\"]\n",
    "    JLD2.@save(joinpath(param_paths[dataset_central][\"path_root_process\"], \"$(dataset)_registered_data_dict.jld2\"), data_dict)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
